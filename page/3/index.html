<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Zyao</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Zyao">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="Zyao">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Zyao" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Zyao</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS 订阅"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-system-design/distributed-system/message-queue/message-queue" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/distributed-system/message-queue/message-queue/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.979Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="消息队列其实很简单"><a href="#消息队列其实很简单" class="headerlink" title="消息队列其实很简单"></a>消息队列其实很简单</h1><p>“RabbitMQ？”“Kafka？”“RocketMQ？”…在日常学习与开发过程中，我们常常听到消息队列这个关键词。我也在我的多篇文章中提到了这个概念。可能你是熟练使用消息队列的老手，又或者你是不懂消息队列的新手，不论你了不了解消息队列，本文都将带你搞懂消息队列的一些基本理论。如果你是老手，你可能从本文学到你之前不曾注意的一些关于消息队列的重要概念，如果你是新手，相信本文将是你打开消息队列大门的一板砖。</p>
<h2 id="一-什么是消息队列"><a href="#一-什么是消息队列" class="headerlink" title="一 什么是消息队列"></a>一 什么是消息队列</h2><p>我们可以把消息队列看作是一个存放消息的容器，当我们需要使用消息的时候，直接从容器中取出消息供自己使用即可。</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/message-queue-small.png" alt="Message queue"></p>
<p>消息队列是分布式系统中重要的组件之一。使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。</p>
<p>我们知道队列 Queue 是一种先进先出的数据结构，所以消费消息时也是按照顺序来消费的。</p>
<h2 id="二-为什么要用消息队列"><a href="#二-为什么要用消息队列" class="headerlink" title="二 为什么要用消息队列"></a>二 为什么要用消息队列</h2><p>通常来说，使用消息队列能为我们的系统带来下面三点好处：</p>
<ol>
<li><strong>通过异步处理提高系统性能（减少响应所需时间）。</strong></li>
<li><strong>削峰/限流</strong></li>
<li><strong>降低系统耦合性。</strong></li>
</ol>
<p>如果在面试的时候你被面试官问到这个问题的话，一般情况是你在你的简历上涉及到消息队列这方面的内容，这个时候推荐你结合你自己的项目来回答。</p>
<p>《大型网站技术架构》第四章和第七章均有提到消息队列对应用性能及扩展性的提升。</p>
<h3 id="2-1-通过异步处理提高系统性能（减少响应所需时间）"><a href="#2-1-通过异步处理提高系统性能（减少响应所需时间）" class="headerlink" title="2.1 通过异步处理提高系统性能（减少响应所需时间）"></a>2.1 通过异步处理提高系统性能（减少响应所需时间）</h3><p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/Asynchronous-message-queue.png" alt="通过异步处理提高系统性能"></p>
<p>将用户的请求数据存储到消息队列之后就立即返回结果。随后，系统再对消息进行消费。</p>
<p>因为用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此，<strong>使用消息队列进行异步处理之后，需要适当修改业务流程进行配合</strong>，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。这就类似我们平时手机订火车票和电影票。</p>
<h3 id="2-2-削峰-限流"><a href="#2-2-削峰-限流" class="headerlink" title="2.2 削峰/限流"></a>2.2 削峰/限流</h3><p><strong>先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。</strong></p>
<p>举例：在电子商务一些秒杀、促销活动中，合理使用消息队列可以有效抵御促销活动刚开始大量订单涌入对系统的冲击。如下图所示：</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E5%89%8A%E5%B3%B0-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97.png" alt="削峰"></p>
<h3 id="2-3-降低系统耦合性"><a href="#2-3-降低系统耦合性" class="headerlink" title="2.3 降低系统耦合性"></a>2.3 降低系统耦合性</h3><p>使用消息队列还可以降低系统耦合性。我们知道如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块影响较小，这样系统的可扩展性无疑更好一些。还是直接上图吧：</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E8%A7%A3%E8%80%A6.png" alt="解耦"></p>
<p>生产者（客户端）发送消息到消息队列中去，接受者（服务端）处理消息，需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合，这显然也提高了系统的扩展性。</p>
<p><strong>消息队列使利用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。</strong> 从上图可以看到<strong>消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合</strong>，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。<strong>对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计</strong>。</p>
<p>消息接受者对消息进行过滤、处理、包装后，构造成一个新的消息类型，将消息继续发送出去，等待其他消息接受者订阅该消息。因此基于事件（消息对象）驱动的业务架构可以是一系列流程。</p>
<p>另外，为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息。</p>
<p><strong>备注：</strong> 不要认为消息队列只能利用发布-订阅模式工作，只不过在解耦这个特定业务环境下是使用发布-订阅模式的。除了发布-订阅模式，还有点对点订阅模式（一个消息只有一个消费者），我们比较常用的是发布-订阅模式。另外，这两种消息模型是 JMS 提供的，AMQP 协议还提供了 5 种消息模型。</p>
<h2 id="三-使用消息队列带来的一些问题"><a href="#三-使用消息队列带来的一些问题" class="headerlink" title="三 使用消息队列带来的一些问题"></a>三 使用消息队列带来的一些问题</h2><ul>
<li><strong>系统可用性降低：</strong> 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！</li>
<li><strong>系统复杂性提高：</strong> 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！</li>
<li><strong>一致性问题：</strong> 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!</li>
</ul>
<h2 id="四-JMS-VS-AMQP"><a href="#四-JMS-VS-AMQP" class="headerlink" title="四 JMS VS AMQP"></a>四 JMS VS AMQP</h2><h3 id="4-1-JMS"><a href="#4-1-JMS" class="headerlink" title="4.1 JMS"></a>4.1 JMS</h3><h4 id="4-1-1-JMS-简介"><a href="#4-1-1-JMS-简介" class="headerlink" title="4.1.1 JMS 简介"></a>4.1.1 JMS 简介</h4><p>JMS（JAVA Message Service,java 消息服务）是 java 的消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。<strong>JMS（JAVA Message Service，Java 消息服务）API 是一个消息服务的标准或者说是规范</strong>，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。</p>
<p><strong>ActiveMQ 就是基于 JMS 规范实现的。</strong></p>
<h4 id="4-1-2-JMS-两种消息模型"><a href="#4-1-2-JMS-两种消息模型" class="headerlink" title="4.1.2 JMS 两种消息模型"></a>4.1.2 JMS 两种消息模型</h4><p><strong>① 点到点（P2P）模型</strong></p>
<p><img src="https://user-gold-cdn.xitu.io/2018/4/21/162e7185572ca37d?w=575&h=135&f=gif&s=8530" alt="点到点（P2P）模型"></p>
<p>使用<strong>队列（Queue）</strong>作为消息通信载体；满足<strong>生产者与消费者模式</strong>，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。比如：我们生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）</p>
<p><strong>② 发布/订阅（Pub/Sub）模型</strong></p>
<p><img src="https://user-gold-cdn.xitu.io/2018/4/21/162e7187c268eaa5?w=402&h=164&f=gif&s=15492" alt="发布/订阅（Pub/Sub）模型"></p>
<p>发布订阅模型（Pub/Sub） 使用<strong>主题（Topic）</strong>作为消息通信载体，类似于<strong>广播模式</strong>；发布者发布一条消息，该消息通过主题传递给所有的订阅者，<strong>在一条消息广播之后才订阅的用户则是收不到该条消息的</strong>。</p>
<h4 id="4-1-3-JMS-五种不同的消息正文格式"><a href="#4-1-3-JMS-五种不同的消息正文格式" class="headerlink" title="4.1.3 JMS 五种不同的消息正文格式"></a>4.1.3 JMS 五种不同的消息正文格式</h4><p>JMS 定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。</p>
<ul>
<li>StreamMessage – Java 原始值的数据流</li>
<li>MapMessage–一套名称-值对</li>
<li>TextMessage–一个字符串对象</li>
<li>ObjectMessage–一个序列化的 Java 对象</li>
<li>BytesMessage–一个字节的数据流</li>
</ul>
<h3 id="4-2-AMQP"><a href="#4-2-AMQP" class="headerlink" title="4.2 AMQP"></a>4.2 AMQP</h3><p>AMQP，即 Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准 <strong>高级消息队列协议</strong>（二进制应用层协议），是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。</p>
<p><strong>RabbitMQ 就是基于 AMQP 协议实现的。</strong></p>
<h3 id="4-3-JMS-vs-AMQP"><a href="#4-3-JMS-vs-AMQP" class="headerlink" title="4.3 JMS vs AMQP"></a>4.3 JMS vs AMQP</h3><table>
<thead>
<tr>
<th align="left">对比方向</th>
<th align="left">JMS</th>
<th align="left">AMQP</th>
</tr>
</thead>
<tbody><tr>
<td align="left">定义</td>
<td align="left">Java API</td>
<td align="left">协议</td>
</tr>
<tr>
<td align="left">跨语言</td>
<td align="left">否</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">跨平台</td>
<td align="left">否</td>
<td align="left">是</td>
</tr>
<tr>
<td align="left">支持消息类型</td>
<td align="left">提供两种消息模型：①Peer-2-Peer;②Pub/sub</td>
<td align="left">提供了五种消息模型：①direct exchange；②fanout exchange；③topic change；④headers exchange；⑤system exchange。本质来讲，后四种和 JMS 的 pub/sub 模型没有太大差别，仅是在路由机制上做了更详细的划分；</td>
</tr>
<tr>
<td align="left">支持消息类型</td>
<td align="left">支持多种消息类型 ，我们在上面提到过</td>
<td align="left">byte[]（二进制）</td>
</tr>
</tbody></table>
<p><strong>总结：</strong></p>
<ul>
<li>AMQP 为消息定义了线路层（wire-level protocol）的协议，而 JMS 所定义的是 API 规范。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而 AMQP 天然具有跨平台、跨语言特性。</li>
<li>JMS 支持 TextMessage、MapMessage 等复杂的消息类型；而 AMQP 仅支持 byte[] 消息类型（复杂的类型可序列化后发送）。</li>
<li>由于 Exchange 提供的路由算法，AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。</li>
</ul>
<h2 id="五-常见的消息队列对比"><a href="#五-常见的消息队列对比" class="headerlink" title="五 常见的消息队列对比"></a>五 常见的消息队列对比</h2><table>
<thead>
<tr>
<th>对比方向</th>
<th>概要</th>
</tr>
</thead>
<tbody><tr>
<td>吞吐量</td>
<td>万级的 ActiveMQ 和 RabbitMQ 的吞吐量（ActiveMQ 的性能最差）要比 十万级甚至是百万级的 RocketMQ 和 Kafka 低一个数量级。</td>
</tr>
<tr>
<td>可用性</td>
<td>都可以实现高可用。ActiveMQ 和 RabbitMQ 都是基于主从架构实现高可用性。RocketMQ 基于分布式架构。 kafka 也是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td>
</tr>
<tr>
<td>时效性</td>
<td>RabbitMQ 基于 erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。其他三个都是 ms 级。</td>
</tr>
<tr>
<td>功能支持</td>
<td>除了 Kafka，其他三个功能都较为完备。 Kafka 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准</td>
</tr>
<tr>
<td>消息丢失</td>
<td>ActiveMQ 和 RabbitMQ 丢失的可能性非常低， RocketMQ 和 Kafka 理论上不会丢失。</td>
</tr>
</tbody></table>
<p><strong>总结：</strong></p>
<ul>
<li>ActiveMQ 的社区算是比较成熟，但是较目前来说，ActiveMQ 的性能比较差，而且版本迭代很慢，不推荐使用。</li>
<li>RabbitMQ 在吞吐量方面虽然稍逊于 Kafka 和 RocketMQ ，但是由于它基于 erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。但是也因为 RabbitMQ 基于 erlang 开发，所以国内很少有公司有实力做 erlang 源码级别的研究和定制。如果业务场景对并发量要求不是太高（十万级、百万级），那这四种消息队列中，RabbitMQ 一定是你的首选。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。</li>
<li>RocketMQ 阿里出品，Java 系开源项目，源代码我们可以直接阅读，然后可以定制自己公司的 MQ，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。RocketMQ 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准 JMS 规范走的有些系统要迁移需要修改大量代码。还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用 RocketMQ 挺好的</li>
<li>Kafka 的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。</li>
</ul>
<p>参考：《Java 工程师面试突击第 1 季-中华石杉老师》</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/distributed-system/message-queue/message-queue/" data-id="cks75dy62000f7kvegmvi8o1y" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/distributed-system/message-queue/Kafka常见面试题总结" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/distributed-system/message-queue/Kafka%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.975Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="Kafka面试题总结"><a href="#Kafka面试题总结" class="headerlink" title="Kafka面试题总结"></a>Kafka面试题总结</h2><h3 id="Kafka-是什么？主要应用场景有哪些？"><a href="#Kafka-是什么？主要应用场景有哪些？" class="headerlink" title="Kafka 是什么？主要应用场景有哪些？"></a>Kafka 是什么？主要应用场景有哪些？</h3><p>Kafka 是一个分布式流式处理平台。这到底是什么意思呢？</p>
<p>流平台具有三个关键功能：</p>
<ol>
<li><strong>消息队列</strong>：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。</li>
<li><strong>容错的持久方式存储记录消息流</strong>： Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险·。</li>
<li><strong>流式处理平台：</strong> 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。</li>
</ol>
<p>Kafka 主要有两大应用场景：</p>
<ol>
<li><strong>消息队列</strong> ：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。</li>
<li><strong>数据处理：</strong> 构建实时的流数据处理程序来转换或处理数据流。</li>
</ol>
<h3 id="和其他消息队列相比-Kafka的优势在哪里？"><a href="#和其他消息队列相比-Kafka的优势在哪里？" class="headerlink" title="和其他消息队列相比,Kafka的优势在哪里？"></a>和其他消息队列相比,Kafka的优势在哪里？</h3><p>我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它给 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下：</p>
<ol>
<li><strong>极致的性能</strong> ：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。</li>
<li><strong>生态系统兼容性无可匹敌</strong> ：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。</li>
</ol>
<p>实际上在早期的时候 Kafka 并不是一个合格的消息队列，早期的 Kafka 在消息队列领域就像是一个衣衫褴褛的孩子一样，功能不完备并且有一些小问题比如丢失消息、不保证消息可靠性等等。当然，这也和 LinkedIn 最早开发 Kafka 用于处理海量的日志有很大关系，哈哈哈，人家本来最开始就不是为了作为消息队列滴，谁知道后面误打误撞在消息队列领域占据了一席之地。</p>
<p>随着后续的发展，这些短板都被 Kafka 逐步修复完善。所以，<strong>Kafka 作为消息队列不可靠这个说法已经过时！</strong></p>
<h3 id="队列模型了解吗？Kafka-的消息模型知道吗？"><a href="#队列模型了解吗？Kafka-的消息模型知道吗？" class="headerlink" title="队列模型了解吗？Kafka 的消息模型知道吗？"></a>队列模型了解吗？Kafka 的消息模型知道吗？</h3><blockquote>
<p>题外话：早期的 JMS 和 AMQP 属于消息服务领域权威组织所做的相关的标准，我在 <a target="_blank" rel="noopener" href="https://github.com/Snailclimb/JavaGuide">JavaGuide</a>的 <a target="_blank" rel="noopener" href="https://github.com/Snailclimb/JavaGuide#%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E4%B8%AD%E9%97%B4%E4%BB%B6">《消息队列其实很简单》</a>这篇文章中介绍过。但是，这些标准的进化跟不上消息队列的演进速度，这些标准实际上已经属于废弃状态。所以，可能存在的情况是：不同的消息队列都有自己的一套消息模型。</p>
</blockquote>
<h4 id="队列模型：早期的消息模型"><a href="#队列模型：早期的消息模型" class="headerlink" title="队列模型：早期的消息模型"></a>队列模型：早期的消息模型</h4><p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B23.png" alt="队列模型"></p>
<p><strong>使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。</strong> 比如：我们生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）</p>
<p><strong>队列模型存在的问题：</strong></p>
<p>假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完成的消息内容。</p>
<p>这种情况，队列模型就不好解决了。很多比较杠精的人就说：我们可以为每个消费者创建一个单独的队列，让生产者发送多份。这是一种非常愚蠢的做法，浪费资源不说，还违背了使用消息队列的目的。</p>
<h4 id="发布-订阅模型-Kafka-消息模型"><a href="#发布-订阅模型-Kafka-消息模型" class="headerlink" title="发布-订阅模型:Kafka 消息模型"></a>发布-订阅模型:Kafka 消息模型</h4><p>发布-订阅模型主要是为了解决队列模型存在的问题。</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/java-guide-blog/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B.png" alt="发布订阅模型"></p>
<p>发布订阅模型（Pub-Sub） 使用<strong>主题（Topic）</strong> 作为消息通信载体，类似于<strong>广播模式</strong>；发布者发布一条消息，该消息通过主题传递给所有的订阅者，<strong>在一条消息广播之后才订阅的用户则是收不到该条消息的</strong>。</p>
<p><strong>在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。</strong></p>
<p><strong>Kafka 采用的就是发布 - 订阅模型。</strong> </p>
<blockquote>
<p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p>
</blockquote>
<h3 id="什么是Producer、Consumer、Broker、Topic、Partition？"><a href="#什么是Producer、Consumer、Broker、Topic、Partition？" class="headerlink" title="什么是Producer、Consumer、Broker、Topic、Partition？"></a>什么是Producer、Consumer、Broker、Topic、Partition？</h3><p>Kafka 将生产者发布的消息发送到 <strong>Topic（主题）</strong> 中，需要这些消息的消费者可以订阅这些 <strong>Topic（主题）</strong>，如下图所示：</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/KafkaTopicPartitioning.png" alt="Kafka Topic Partition"></p>
<p>上面这张图也为我们引出了，Kafka 比较重要的几个概念：</p>
<ol>
<li><strong>Producer（生产者）</strong> : 产生消息的一方。</li>
<li><strong>Consumer（消费者）</strong> : 消费消息的一方。</li>
<li><strong>Broker（代理）</strong> : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。</li>
</ol>
<p>同时，你一定也注意到每个 Broker 中又包含了 Topic 以及 Partition 这两个重要的概念：</p>
<ul>
<li><strong>Topic（主题）</strong> : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。</li>
<li><strong>Partition（分区）</strong> : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。</li>
</ul>
<blockquote>
<p>划重点：<strong>Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。这样是不是更好理解一点？</strong></p>
</blockquote>
<h3 id="Kafka-的多副本机制了解吗？带来了什么好处？"><a href="#Kafka-的多副本机制了解吗？带来了什么好处？" class="headerlink" title="Kafka 的多副本机制了解吗？带来了什么好处？"></a>Kafka 的多副本机制了解吗？带来了什么好处？</h3><p>还有一点我觉得比较重要的是 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。</p>
<blockquote>
<p>生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。</p>
</blockquote>
<p><strong>Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？</strong></p>
<ol>
<li>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</li>
<li>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</li>
</ol>
<h3 id="Zookeeper-在-Kafka-中的作用知道吗？"><a href="#Zookeeper-在-Kafka-中的作用知道吗？" class="headerlink" title="Zookeeper 在 Kafka 中的作用知道吗？"></a>Zookeeper 在 Kafka 中的作用知道吗？</h3><blockquote>
<p><strong>要想搞懂 zookeeper 在 Kafka 中的作用 一定要自己搭建一个 Kafka 环境然后自己进 zookeeper 去看一下有哪些文件夹和 Kafka 有关，每个节点又保存了什么信息。</strong> 一定不要光看不实践，这样学来的也终会忘记！这部分内容参考和借鉴了这篇文章：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/a036405f989c">https://www.jianshu.com/p/a036405f989c</a> 。</p>
</blockquote>
<p>下图就是我的本地 Zookeeper ，它成功和我本地的 Kafka 关联上（以下文件夹结构借助 idea 插件 Zookeeper tool 实现）。</p>
<img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/zookeeper-kafka.jpg" style="zoom:50%;" />

<p>ZooKeeper 主要为 Kafka 提供元数据的管理的功能。</p>
<p>从图中我们可以看出，Zookeeper 主要为 Kafka 做了下面这些事情：</p>
<ol>
<li><strong>Broker 注册</strong> ：在 Zookeeper 上会有一个专门<strong>用来进行 Broker 服务器列表记录</strong>的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去</li>
<li><strong>Topic 注册</strong> ： 在 Kafka 中，同一个<strong>Topic 的消息会被分成多个分区</strong>并将其分布在多个 Broker 上，<strong>这些分区信息及与 Broker 的对应关系</strong>也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：<code>/brokers/topics/my-topic/Partitions/0</code>、<code>/brokers/topics/my-topic/Partitions/1</code></li>
<li><strong>负载均衡</strong> ：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。</li>
<li>……</li>
</ol>
<h3 id="Kafka-如何保证消息的消费顺序？"><a href="#Kafka-如何保证消息的消费顺序？" class="headerlink" title="Kafka 如何保证消息的消费顺序？"></a>Kafka 如何保证消息的消费顺序？</h3><p>我们在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如我们同时发了 2 个消息，这 2 个消息对应的操作分别对应的数据库操作是：更改用户会员等级、根据会员等级计算订单价格。假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。</p>
<p>我们知道 Kafka 中 Partition(分区)是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的 Partition(分区) 又存在于 Topic(主题) 这个概念中，并且我们可以给特定 Topic 指定多个 Partition。</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/KafkaTopicPartionsLayout.png"></p>
<p>每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。Kafka 只能为我们保证 Partition(分区) 中的消息有序，而不能保证 Topic(主题) 中的 Partition(分区) 的有序。</p>
<blockquote>
<p>消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。</p>
</blockquote>
<p>所以，我们就有一种很简单的保证消息消费顺序的方法：<strong>1 个 Topic 只对应一个 Partition</strong>。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。</p>
<p>Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。</p>
<p>总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法：</p>
<ol>
<li>1 个 Topic 只对应一个 Partition。</li>
<li>（推荐）发送消息的时候指定 key/Partition。</li>
</ol>
<p>当然不仅仅只有上面两种方法，上面两种方法是我觉得比较好理解的，</p>
<h3 id="Kafka-如何保证消息不丢失"><a href="#Kafka-如何保证消息不丢失" class="headerlink" title="Kafka 如何保证消息不丢失"></a>Kafka 如何保证消息不丢失</h3><h4 id="生产者丢失消息的情况"><a href="#生产者丢失消息的情况" class="headerlink" title="生产者丢失消息的情况"></a>生产者丢失消息的情况</h4><p>生产者(Producer) 调用<code>send</code>方法发送消息之后，消息可能因为网络问题并没有发送过去。 </p>
<p>所以，我们不能默认在调用<code>send</code>方法发送消息之后消息消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是  Kafka 生产者(Producer) 使用  <code>send</code> 方法发送消息实际上是异步的操作，我们可以通过 <code>get()</code>方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：</p>
<blockquote>
<p><strong>详细代码见我的这篇文章：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247486269&idx=2&sn=ec00417ad641dd8c3d145d74cafa09ce&chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de&token=1633957262&lang=zh_CN#rd">Kafka系列第三篇！10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?</a></strong></p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SendResult&lt;String, Object&gt; sendResult = kafkaTemplate.send(topic, o).get();</span><br><span class="line"><span class="keyword">if</span> (sendResult.getRecordMetadata() != <span class="keyword">null</span>) &#123;</span><br><span class="line">  logger.info(<span class="string">&quot;生产者成功发送消息到&quot;</span> + sendResult.getProducerRecord().topic() + <span class="string">&quot;-&gt; &quot;</span> + sendRe</span><br><span class="line">              sult.getProducerRecord().value().toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(topic, o);</span><br><span class="line">future.addCallback(result -&gt; logger.info(<span class="string">&quot;生产者成功发送消息到topic:&#123;&#125; partition:&#123;&#125;的消息&quot;</span>, result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),</span><br><span class="line">        ex -&gt; logger.error(<span class="string">&quot;生产者发送消失败，原因：&#123;&#125;&quot;</span>, ex.getMessage()));</span><br></pre></td></tr></table></figure>

<p>如果消息发送失败的话，我们检查失败的原因之后重新发送即可！</p>
<p><strong>另外这里推荐为 Producer 的<code>retries </code>（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你3次一下子就重试完了</strong></p>
<h4 id="消费者丢失消息的情况"><a href="#消费者丢失消息的情况" class="headerlink" title="消费者丢失消息的情况"></a>消费者丢失消息的情况</h4><p>我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/kafka-offset.jpg" alt="kafka offset"></p>
<p>当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。</p>
<p><strong>解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后之后再自己手动提交 offset 。</strong> 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。</p>
<h4 id="Kafka-弄丢了消息"><a href="#Kafka-弄丢了消息" class="headerlink" title="Kafka 弄丢了消息"></a>Kafka 弄丢了消息</h4><p> 我们知道 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。</p>
<p><strong>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</strong></p>
<p><strong>设置 acks = all</strong></p>
<p>解决办法就是我们设置  <strong>acks = all</strong>。acks 是 Kafka 生产者(Producer)  很重要的一个参数。</p>
<p>acks 的默认值即为1，代表我们的消息被leader副本接收之后就算被成功发送。当我们配置 <strong>acks = all</strong> 代表则所有副本都要接收到该消息之后该消息才算真正成功被发送。</p>
<p><strong>设置 replication.factor &gt;= 3</strong></p>
<p>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 <strong>replication.factor &gt;= 3</strong>。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p>
<p><strong>设置 min.insync.replicas &gt; 1</strong></p>
<p>一般情况下我们还需要设置 <strong>min.insync.replicas&gt; 1</strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p>
<p>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 <strong>replication.factor &gt; min.insync.replicas</strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong>replication.factor = min.insync.replicas + 1</strong>。</p>
<p><strong>设置 unclean.leader.election.enable = false</strong></p>
<blockquote>
<p><strong>Kafka 0.11.0.0版本开始 unclean.leader.election.enable 参数的默认值由原来的true 改为false</strong></p>
</blockquote>
<p>我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 <strong>unclean.leader.election.enable = false</strong>  的话，当 leader 副本发生故障时就不会从  follower 副本中和 leader 同步程度达不到要求的副本中选择出  leader ，这样降低了消息丢失的可能性。</p>
<h3 id="Kafka-如何保证消息不重复消费"><a href="#Kafka-如何保证消息不重复消费" class="headerlink" title="Kafka 如何保证消息不重复消费"></a>Kafka 如何保证消息不重复消费</h3><p>代办…</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li>Kafka 官方文档： <a target="_blank" rel="noopener" href="https://kafka.apache.org/documentation/">https://kafka.apache.org/documentation/</a></li>
<li>极客时间—《Kafka核心技术与实战》第11节：无消息丢失配置怎么实现？</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/distributed-system/message-queue/Kafka%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/" data-id="cks75dy69000l7kvefg3lah2b" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/distributed-system/api-gateway/为什么要网站有哪些常见的网站系统" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/distributed-system/api-gateway/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%BD%91%E7%AB%99%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E7%AB%99%E7%B3%BB%E7%BB%9F/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.965Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="为什么要网关？"><a href="#为什么要网关？" class="headerlink" title="为什么要网关？"></a>为什么要网关？</h3><p>微服务下一个系统被拆分为多个服务，但是像 安全认证，流量控制，日志，监控等功能是每个服务都需要的，没有网关的话，我们就需要在每个服务中单独实现，这使得我们做了很多重复的事情并且没有一个全局的视图来统一管理这些功能。</p>
<p>综上：<strong>一般情况下，网关一般都会提供请求转发、安全认证（身份/权限认证）、流量控制、负载均衡、容灾、日志、监控这些功能。</strong></p>
<p>上面介绍了这么多功能实际上网关主要做了一件事情：<strong>请求过滤</strong> 。权限校验、流量控制这些都可以通过过滤器实现，请求转也是通过过滤器实现的。</p>
<h3 id="你知道有哪些常见的网关系统？"><a href="#你知道有哪些常见的网关系统？" class="headerlink" title="你知道有哪些常见的网关系统？"></a>你知道有哪些常见的网关系统？</h3><p>我所了解的目前经常用到的开源 API 网关系统有：</p>
<ol>
<li>Kong</li>
<li>Netflix zuul</li>
</ol>
<p>下图来源：<a target="_blank" rel="noopener" href="https://www.stackshare.io/stackups/kong-vs-zuul">https://www.stackshare.io/stackups/kong-vs-zuul</a> 。</p>
<p><img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/kong-vs-zuul.jpg" alt="Kong vs Netflix zuul"></p>
<p>可以看出不论是社区活跃度还是 Star数， Kong 都是略胜一筹。总的来说，Kong 相比于 Zuul 更加强大并且简单易用。Kong 基于 Openresty ，Zuul 基于 Java。</p>
<blockquote>
<p>OpenResty（也称为 ngx_openresty）是一个全功能的 Web 应用服务器。它打包了标准的 Nginx 核心，很多的常用的第三方模块，以及它们的大多数依赖项。</p>
<p>通过揉和众多设计良好的 Nginx 模块，OpenResty 有效地把 Nginx 服务器转变为一个强大的 Web 应用服务器，基于它开发人员可以使用 Lua 编程语言对 Nginx 核心以及现有的各种 Nginx C 模块进行脚本编程，构建出可以处理一万以上并发请求的极端高性能的 Web 应用。——OpenResty</p>
</blockquote>
<p>另外， Kong 还提供了插件机制来扩展其功能。</p>
<p>比如、在服务上启用 Zipkin 插件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> curl -X POST http://kong:8001/services/&#123;service&#125;/plugins \</span></span><br><span class="line"><span class="bash">    --data <span class="string">&quot;name=zipkin&quot;</span>  \</span></span><br><span class="line"><span class="bash">    --data <span class="string">&quot;config.http_endpoint=http://your.zipkin.collector:9411/api/v2/spans&quot;</span> \</span></span><br><span class="line"><span class="bash">    --data <span class="string">&quot;config.sample_ratio=0.001&quot;</span></span></span><br></pre></td></tr></table></figure>

<p>ps:这里没有太深入去探讨，需要深入了解的话可以自行查阅相关资料。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/distributed-system/api-gateway/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%BD%91%E7%AB%99%E6%9C%89%E5%93%AA%E4%BA%9B%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E7%AB%99%E7%B3%BB%E7%BB%9F/" data-id="cks75dy60000d7kve87dz5k3y" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/distributed-system/CAP理论" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/distributed-system/CAP%E7%90%86%E8%AE%BA/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.959Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>经历过技术面试的小伙伴想必对这个两个概念已经再熟悉不过了！</p>
<p>Guide哥当年参加面试的时候，不夸张地说，只要问到分布式相关的内容，面试官几乎是必定会问这两个分布式相关的理论。</p>
<p>并且，这两个理论也可以说是小伙伴们学习分布式相关内容的基础了！</p>
<p>因此，小伙伴们非常非常有必要将这理论搞懂，并且能够用自己的理解给别人讲出来。</p>
<p>这篇文章我会站在自己的角度对这两个概念进行解读！</p>
<p><em>个人能力有限。如果文章有任何需要改善和完善的地方，欢迎在评论区指出，共同进步！——爱你们的Guide哥</em></p>
<h2 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h2><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/CAP%E5%AE%9A%E7%90%86">CAP 理论/定理</a>起源于 2000年，由加州大学伯克利分校的Eric Brewer教授在分布式计算原理研讨会（PODC）上提出，因此 CAP定理又被称作 <strong>布鲁尔定理（Brewer’s theorem）</strong></p>
<p>2年后，麻省理工学院的Seth Gilbert和Nancy Lynch 发表了布鲁尔猜想的证明，CAP理论正式成为分布式领域的定理。</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>CAP</strong> 也就是 <strong>Consistency（一致性）</strong>、<strong>Availability（可用性）</strong>、<strong>Partition Tolerance（分区容错性）</strong> 这三个单词首字母组合。</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/cap.png"></p>
<p>CAP 理论的提出者布鲁尔在提出 CAP 猜想的时候，并没有详细定义 <strong>Consistency</strong>、<strong>Availability</strong>、<strong>Partition Tolerance</strong> 三个单词的明确定义。</p>
<p>因此，对于 CAP 的民间解读有很多，一般比较被大家推荐的是下面 👇 这种版本的解。</p>
<p>在理论计算机科学中，CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能能同时满足以下三点中的两个：</p>
<ul>
<li><strong>一致性（Consistence）</strong> : 所有节点访问同一份最新的数据副本</li>
<li><strong>可用性（Availability）</strong>: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li>
<li><strong>分区容错性（Partition tolerance）</strong> : 分布式系统出现网络分区的时候，仍然能够对外提供服务。</li>
</ul>
<p><strong>什么是网络分区？</strong></p>
<blockquote>
<p>分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫网络分区。</p>
</blockquote>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/partition-tolerance.png" alt="partition-tolerance"></p>
<h3 id="不是所谓的“3-选-2”"><a href="#不是所谓的“3-选-2”" class="headerlink" title="不是所谓的“3 选 2”"></a>不是所谓的“3 选 2”</h3><p>大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。</p>
<blockquote>
<p><strong>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</strong></p>
<p>简而言之就是：CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。</p>
</blockquote>
<p>因此，<strong>分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong> 比如  ZooKeeper、HBase 就是 CP 架构，Cassandra、Eureka 就是 AP 架构，Nacos 不仅支持 CP 架构也支持 AP 架构。</p>
<p><strong>为啥不可能选择 CA 架构呢？</strong> 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。</p>
<p><strong>选择 CP 还是 AP 的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。</strong></p>
<p>另外，需要补充说明的一点是： <strong>如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。</strong></p>
<h3 id="CAP-实际应用案例"><a href="#CAP-实际应用案例" class="headerlink" title="CAP 实际应用案例"></a>CAP 实际应用案例</h3><p>我这里以注册中心来探讨一下 CAP 的实际应用。考虑到很多小伙伴不知道注册中心是干嘛的，这里简单以 Dubbo 为例说一说。</p>
<p>下图是 Dubbo 的架构图。<strong>注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？</strong></p>
<p>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/dubbo-architecture.png"></p>
<p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。</p>
<ol>
<li><strong>ZooKeeper 保证的是 CP。</strong> 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li>
<li><strong>Eureka 保证的则是 AP。</strong> Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。</li>
<li><strong>Nacos 不仅支持 CP 也支持 AP。</strong></li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在进行分布式系统设计和开发时，我们不应该仅仅局限在 CAP 问题上，还要关注系统的扩展性、可用性等等</p>
<p>在系统发生“分区”的情况下，CAP 理论只能满足 CP 或者 AP。要注意的是，这里的前提是系统发生了“分区”</p>
<p>如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。</p>
<p>总结：<strong>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。</strong></p>
<h3 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h3><ol>
<li><a target="_blank" rel="noopener" href="https://medium.com/@ravindraprasad/cap-theorem-simplified-28499a67eab4">CAP 定理简化</a> （英文，有趣的案例）</li>
<li><a target="_blank" rel="noopener" href="https://juejin.im/post/6844903936718012430">神一样的 CAP 理论被应用在何方</a> （中文，列举了很多实际的例子）</li>
<li><a target="_blank" rel="noopener" href="https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html">请停止呼叫数据库 CP 或 AP </a> （英文，带给你不一样的思考）</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/distributed-system/CAP%E7%90%86%E8%AE%BA/" data-id="cks75dy5u00087kvedvma9532" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/distributed-system/BASE理论" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/distributed-system/BASE%E7%90%86%E8%AE%BA/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.955Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="BASE-理论"><a href="#BASE-理论" class="headerlink" title="BASE 理论"></a>BASE 理论</h2><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/1394127.1394128">BASE 理论</a>起源于 2008 年， 由eBay的架构师Dan Pritchett在ACM上发表。</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p><strong>BASE</strong> 是 <strong>Basically Available（基本可用）</strong> 、<strong>Soft-state（软状态）</strong> 和 <strong>Eventually Consistent（最终一致性）</strong> 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。</p>
<h3 id="BASE-理论的核心思想"><a href="#BASE-理论的核心思想" class="headerlink" title="BASE 理论的核心思想"></a>BASE 理论的核心思想</h3><p>即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。</p>
<blockquote>
<p>也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。</p>
</blockquote>
<p><strong>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</strong></p>
<p><strong>为什么这样说呢？</strong></p>
<p>CAP 理论这节我们也说过了：</p>
<blockquote>
<p>如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，<strong>如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。</strong></p>
</blockquote>
<p>因此，AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。</p>
<h3 id="BASE-理论三要素"><a href="#BASE-理论三要素" class="headerlink" title="BASE 理论三要素"></a>BASE 理论三要素</h3><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAxOC81LzI0LzE2MzkxNDgwNmQ5ZTE1YzY?x-oss-process=image/format,png" alt="BASE理论三要素"></p>
<h4 id="1-基本可用"><a href="#1-基本可用" class="headerlink" title="1. 基本可用"></a>1. 基本可用</h4><p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。</p>
<p><strong>什么叫允许损失部分可用性呢？</strong></p>
<ul>
<li><strong>响应时间上的损失</strong>: 正常情况下，处理用户请求需要 0.5s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。</li>
<li><strong>系统功能上的损失</strong>：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li>
</ul>
<h4 id="2-软状态"><a href="#2-软状态" class="headerlink" title="2. 软状态"></a>2. 软状态</h4><p>软状态指允许系统中的数据存在中间状态（<strong>CAP 理论中的数据不一致</strong>），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<h4 id="3-最终一致性"><a href="#3-最终一致性" class="headerlink" title="3. 最终一致性"></a>3. 最终一致性</h4><p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p>
<blockquote>
<p>分布式一致性的 3 种级别：</p>
<ol>
<li><p><strong>强一致性</strong> ：系统写入了什么，读出来的就是什么。</p>
</li>
<li><p><strong>弱一致性</strong> ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</p>
</li>
<li><p><strong>最终一致性</strong> ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</p>
</li>
</ol>
<p><strong>业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。</strong></p>
</blockquote>
<p>那实现最终一致性的具体方式是什么呢? <a target="_blank" rel="noopener" href="http://gk.link/a/10rZM">《分布式协议与算法实战》</a> 中是这样介绍：</p>
<blockquote>
<ul>
<li><strong>读时修复</strong> : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点 的副本数据不一致，系统就自动修复数据。</li>
<li><strong>写时修复</strong> : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。</li>
<li> <strong>异步修复</strong> : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。</li>
</ul>
</blockquote>
<p>比较推荐 <strong>写时修复</strong>，这种方式对性能消耗比较低。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</strong></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/distributed-system/BASE%E7%90%86%E8%AE%BA/" data-id="cks75dy5s00067kve7qxl0ajs" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/coding-way/RESTfulAPI简明教程" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/coding-way/RESTfulAPI%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.948Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><img src="https://img-blog.csdnimg.cn/2021050713553862.png"></p>
<p>大家好，我是 Guide哥！</p>
<p>这篇文章简单聊聊后端程序员必备的 RESTful API 相关的知识。</p>
<p>开始正式介绍 RESTful API 之前，我们需要首先搞清 ：<strong>API 到底是什么？</strong></p>
<h2 id="何为-API？"><a href="#何为-API？" class="headerlink" title="何为 API？"></a>何为 API？</h2><p><img src="https://img-blog.csdnimg.cn/20210507153833945.png"></p>
<p><strong>API（Application Programming Interface）</strong> 翻译过来是应用程序编程接口的意思。</p>
<p>我们在进行后端开发的时候，主要的工作就是为前端或者其他后端服务提供 API 比如查询用户数据的 API 。</p>
<p><img src="https://img-blog.csdnimg.cn/20210507130629538.png"></p>
<p>但是， API 不仅仅代表后端系统暴露的接口，像框架中提供的方法也属于 API 的范畴。</p>
<p>为了方便大家理解，我再列举几个例子 🌰：</p>
<ol>
<li>你通过某电商网站搜索某某商品，电商网站的前端就调用了后端提供了搜索商品相关的 API。</li>
<li>你使用 JDK 开发 Java 程序，想要读取用户的输入的话，你就需要使用 JDK 提供的 IO 相关的 API。</li>
<li>……</li>
</ol>
<p>你可以把 API 理解为程序与程序之间通信的桥梁，其本质就是一个函数而已。另外，API 的使用也不是没有章法的，它的规则由（比如数据输入和输出的格式）API 提供方制定。</p>
<h2 id="何为-RESTful-API？"><a href="#何为-RESTful-API？" class="headerlink" title="何为 RESTful API？"></a>何为 RESTful API？</h2><p><strong>RESTful API</strong> 经常也被叫做 <strong>REST API</strong>，它是基于 REST 构建的 API。这个 REST 到底是什么，我们后文在讲，涉及到的概念比较多。</p>
<p>如果你看 RESTful API 相关的文章的话一般都比较晦涩难懂，主要是因为 REST 涉及到的一些概念比较难以理解。但是，实际上，我们平时开发用到的 RESTful API 的知识非常简单也很容易概括！</p>
<p>举个例子，如果我给你下面两个 API 你是不是立马能知道它们是干什么用的！这就是 RESTful API 的强大之处！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET    /classes：列出所有班级</span><br><span class="line">POST   /classes：新建一个班级</span><br></pre></td></tr></table></figure>

<p><strong>RESTful API 可以让你看到 URL+Http Method 就知道这个 URL 是干什么的，让你看到了 HTTP 状态码（status code）就知道请求结果如何。</strong></p>
<p>像咱们在开发过程中设计 API 的时候也应该至少要满足 RESTful API 的最基本的要求（比如接口中尽量使用名词，使用 <code>POST</code> 请求创建资源，<code>DELETE</code> 请求删除资源等等，示例：<code>GET /notes/id</code>：获取某个指定 id 的笔记的信息）。</p>
<h2 id="解读-REST"><a href="#解读-REST" class="headerlink" title="解读 REST"></a>解读 REST</h2><p><strong>REST</strong> 是 <code>REpresentational State Transfer</code> 的缩写。这个词组的翻译过来就是“<strong>表现层状态转化</strong>”。</p>
<p>这样理解起来甚是晦涩，实际上 REST 的全称是 <strong>Resource Representational State Transfer</strong> ，直白地翻译过来就是 <strong>“资源”在网络传输中以某种“表现形式”进行“状态转移”</strong> 。如果还是不能继续理解，请继续往下看，相信下面的讲解一定能让你理解到底啥是 REST 。</p>
<p>我们分别对上面涉及到的概念进行解读，以便加深理解，实际上你不需要搞懂下面这些概念，也能看懂我下一部分要介绍到的内容。不过，为了更好地能跟别人扯扯 “RESTful API”我建议你还是要好好理解一下！</p>
<ul>
<li><strong>资源（Resource）</strong> ：我们可以把真实的对象数据称为资源。一个资源既可以是一个集合，也可以是单个个体。比如我们的班级 classes 是代表一个集合形式的资源，而特定的 class 代表单个个体资源。每一种资源都有特定的 URI（统一资源标识符）与之对应，如果我们需要获取这个资源，访问这个 URI 就可以了，比如获取特定的班级：<code>/class/12</code>。另外，资源也可以包含子资源，比如 <code>/classes/classId/teachers</code>：列出某个指定班级的所有老师的信息</li>
<li><strong>表现形式（Representational）</strong>：”资源”是一种信息实体，它可以有多种外在表现形式。我们把”资源”具体呈现出来的形式比如 <code>json</code>，<code>xml</code>，<code>image</code>,<code>txt</code> 等等叫做它的”表现层/表现形式”。</li>
<li><strong>状态转移（State Transfer）</strong> ：大家第一眼看到这个词语一定会很懵逼？内心 BB：这尼玛是啥啊？ 大白话来说 REST 中的状态转移更多地描述的服务器端资源的状态，比如你通过增删改查（通过 HTTP 动词实现）引起资源状态的改变。ps:互联网通信协议 HTTP 协议，是一个无状态协议，所有的资源状态都保存在服务器端。</li>
</ul>
<p>综合上面的解释，我们总结一下什么是 RESTful 架构：</p>
<ol>
<li>每一个 URI 代表一种资源；</li>
<li>客户端和服务器之间，传递这种资源的某种表现形式比如 <code>json</code>，<code>xml</code>，<code>image</code>,<code>txt</code> 等等；</li>
<li>客户端通过特定的 HTTP 动词，对服务器端资源进行操作，实现”表现层状态转化”。</li>
</ol>
<h2 id="RESTful-API-规范"><a href="#RESTful-API-规范" class="headerlink" title="RESTful API 规范"></a>RESTful API 规范</h2><p><img src="https://img-blog.csdnimg.cn/20210507154007779.png"></p>
<h3 id="动作"><a href="#动作" class="headerlink" title="动作"></a>动作</h3><ul>
<li><code>GET</code>：请求从服务器获取特定资源。举个例子：<code>GET /classes</code>（获取所有班级）</li>
<li><code>POST</code> ：在服务器上创建一个新的资源。举个例子：<code>POST /classes</code>（创建班级）</li>
<li><code>PUT</code> ：更新服务器上的资源（客户端提供更新后的整个资源）。举个例子：<code>PUT /classes/12</code>（更新编号为 12 的班级）</li>
<li><code>DELETE</code> ：从服务器删除特定的资源。举个例子：<code>DELETE /classes/12</code>（删除编号为 12 的班级）</li>
<li><code>PATCH</code> ：更新服务器上的资源（客户端提供更改的属性，可以看做作是部分更新），使用的比较少，这里就不举例子了。</li>
</ul>
<h3 id="路径（接口命名）"><a href="#路径（接口命名）" class="headerlink" title="路径（接口命名）"></a>路径（接口命名）</h3><p>路径又称”终点”（endpoint），表示 API 的具体网址。实际开发中常见的规范如下：</p>
<ol>
<li><strong>网址中不能有动词，只能有名词，API 中的名词也应该使用复数。</strong>因为 REST 中的资源往往和数据库中的表对应，而数据库中的表都是同种记录的”集合”（collection）。如果 API 调用并不涉及资源（如计算，翻译等操作）的话，可以用动词。比如：<code>GET /calculate?param1=11&amp;param2=33</code> 。</li>
<li><strong>不用大写字母，建议用中杠 - 不用下杠 _</strong> 。比如邀请码写成 <code>invitation-code</code>而不是 <del>invitation_code</del> 。</li>
<li><strong>善用版本化 API</strong>。当我们的 API 发生了重大改变而不兼容前期版本的时候，我们可以通过 URL 来实现版本化，比如 <code>Http://api.example.com/v1</code>、<code>http://apiv1.example.com</code> 。版本不必非要是数字，只是数字用的最多，日期、季节都可以作为版本标识符，项目团队达成共识就可。</li>
<li><strong>接口尽量使用名词，避免使用动词。</strong> RESTful API 操作（HTTP Method）的是资源（名词）而不是动作（动词）。</li>
</ol>
<p>Talk is cheap！来举个实际的例子来说明一下吧！现在有这样一个 API 提供班级（class）的信息，还包括班级中的学生和教师的信息，则它的路径应该设计成下面这样。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET    /classes：列出所有班级</span><br><span class="line">POST   /classes：新建一个班级</span><br><span class="line">GET    /classes/classId：获取某个指定班级的信息</span><br><span class="line">PUT    /classes/classId：更新某个指定班级的信息（一般倾向整体更新）</span><br><span class="line">PATCH  /classes/classId：更新某个指定班级的信息（一般倾向部分更新）</span><br><span class="line">DELETE /classes/classId：删除某个班级</span><br><span class="line">GET    /classes/classId/teachers：列出某个指定班级的所有老师的信息</span><br><span class="line">GET    /classes/classId/students：列出某个指定班级的所有学生的信息</span><br><span class="line">DELETE classes/classId/teachers/ID：删除某个指定班级下的指定的老师的信息</span><br></pre></td></tr></table></figure>

<p>反例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/getAllclasses</span><br><span class="line">/createNewclass</span><br><span class="line">/deleteAllActiveclasses</span><br></pre></td></tr></table></figure>

<p>理清资源的层次结构，比如业务针对的范围是学校，那么学校会是一级资源:<code>/schools</code>，老师: <code>/schools/teachers</code>，学生: <code>/schools/students</code> 就是二级资源。</p>
<h3 id="过滤信息（Filtering）"><a href="#过滤信息（Filtering）" class="headerlink" title="过滤信息（Filtering）"></a>过滤信息（Filtering）</h3><p>如果我们在查询的时候需要添加特定条件的话，建议使用 url 参数的形式。比如我们要查询 state 状态为 active 并且 name 为 guidegege 的班级：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET    /classes?state=active&amp;name=guidegege</span><br></pre></td></tr></table></figure>

<p>比如我们要实现分页查询：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET    /classes?page=1&amp;size=10 //指定第1页，每页10个数据</span><br></pre></td></tr></table></figure>

<h3 id="状态码（Status-Codes）"><a href="#状态码（Status-Codes）" class="headerlink" title="状态码（Status Codes）"></a>状态码（Status Codes）</h3><p><strong>状态码范围：</strong></p>
<table>
<thead>
<tr>
<th>2xx：成功</th>
<th>3xx：重定向</th>
<th>4xx：客户端错误</th>
<th>5xx：服务器错误</th>
</tr>
</thead>
<tbody><tr>
<td>200 成功</td>
<td>301 永久重定向</td>
<td>400 错误请求</td>
<td>500 服务器错误</td>
</tr>
<tr>
<td>201 创建</td>
<td>304 资源未修改</td>
<td>401 未授权</td>
<td>502 网关错误</td>
</tr>
<tr>
<td></td>
<td></td>
<td>403 禁止访问</td>
<td>504 网关超时</td>
</tr>
<tr>
<td></td>
<td></td>
<td>404 未找到</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>405 请求方法不对</td>
<td></td>
</tr>
</tbody></table>
<h2 id="RESTful-的极致-HATEOAS"><a href="#RESTful-的极致-HATEOAS" class="headerlink" title="RESTful 的极致 HATEOAS"></a>RESTful 的极致 HATEOAS</h2><blockquote>
<p><strong>RESTful 的极致是 hateoas ，但是这个基本不会在实际项目中用到。</strong></p>
</blockquote>
<p>上面是 RESTful API 最基本的东西，也是我们平时开发过程中最容易实践到的。实际上，RESTful API 最好做到 Hypermedia，即返回结果中提供链接，连向其他 API 方法，使得用户不查文档，也知道下一步应该做什么。</p>
<p>比如，当用户向 <code>api.example.com</code> 的根目录发出请求，会得到这样一个返回结果</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&quot;link&quot;</span>: &#123;</span><br><span class="line">  <span class="string">&quot;rel&quot;</span>:   <span class="string">&quot;collection https://www.example.com/classes&quot;</span>,</span><br><span class="line">  <span class="string">&quot;href&quot;</span>:  <span class="string">&quot;https://api.example.com/classes&quot;</span>,</span><br><span class="line">  <span class="string">&quot;title&quot;</span>: <span class="string">&quot;List of classes&quot;</span>,</span><br><span class="line">  <span class="string">&quot;type&quot;</span>:  <span class="string">&quot;application/vnd.yourformat+json&quot;</span></span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>上面代码表示，文档中有一个 <code>link</code> 属性，用户读取这个属性就知道下一步该调用什么 API 了。<code>rel</code> 表示这个 API 与当前网址的关系（collection 关系，并给出该 collection 的网址），<code>href</code> 表示 API 的路径，title 表示 API 的标题，<code>type</code> 表示返回类型 <code>Hypermedia API</code> 的设计被称为<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/HATEOAS">HATEOAS</a>。</p>
<p>在 Spring 中有一个叫做 HATEOAS 的 API 库，通过它我们可以更轻松的创建除符合 HATEOAS 设计的 API。相关文章：</p>
<ul>
<li><a href="a">在 Spring Boot 中使用 HATEOAS</a></li>
<li><a target="_blank" rel="noopener" href="https://spring.io/guides/tutorials/classmarks/">Building REST services with Spring</a> (Spring 官网 )</li>
<li><a target="_blank" rel="noopener" href="https://www.baeldung.com/spring-hateoas-tutorial">An Intro to Spring HATEOAS</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/spring-projects/spring-hateoas-examples/tree/master/hypermedia">spring-hateoas-examples</a></li>
<li><a target="_blank" rel="noopener" href="https://spring.io/projects/spring-hateoas#learn">Spring HATEOAS</a> (Spring 官网 )</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://restfulapi.net/">https://RESTfulapi.net/</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2014/05/RESTful_api.html">http://www.ruanyifeng.com/blog/2014/05/RESTful_api.html</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://juejin.im/entry/59e460c951882542f578f2f0">https://juejin.im/entry/59e460c951882542f578f2f0</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://phauer.com/2016/testing-RESTful-services-java-best-practices/">https://phauer.com/2016/testing-RESTful-services-java-best-practices/</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.seobility.net/en/wiki/REST_API">https://www.seobility.net/en/wiki/REST_API</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://dev.to/duomly/rest-api-vs-graphql-comparison-3j6g">https://dev.to/duomly/rest-api-vs-graphql-comparison-3j6g</a></p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/coding-way/RESTfulAPI%E7%AE%80%E6%98%8E%E6%95%99%E7%A8%8B/" data-id="cks75dy5t00077kve98x417qa" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/authority-certification/SSO单点登录看这一篇就够了" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/authority-certification/SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.897Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <blockquote>
<p>本文授权转载自 ： <a target="_blank" rel="noopener" href="https://ken.io/note/sso-design-implement">https://ken.io/note/sso-design-implement</a> 作者：ken.io</p>
<p>相关推荐阅读：**<a target="_blank" rel="noopener" href="https://www.imooc.com/article/286710">系统的讲解 - SSO单点登录</a>**</p>
</blockquote>
<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><h3 id="1、SSO说明"><a href="#1、SSO说明" class="headerlink" title="1、SSO说明"></a>1、SSO说明</h3><p>SSO英文全称Single Sign On，单点登录。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/SSO/3451380">https://baike.baidu.com/item/SSO/3451380</a></p>
<p>例如访问在网易账号中心（<a target="_blank" rel="noopener" href="https://reg.163.com/">https://reg.163.com/</a> ）登录之后<br>访问以下站点都是登录状态</p>
<ul>
<li>网易直播 <a target="_blank" rel="noopener" href="https://v.163.com/">https://v.163.com</a></li>
<li>网易博客 <a target="_blank" rel="noopener" href="https://blog.163.com/">https://blog.163.com</a></li>
<li>网易花田 <a target="_blank" rel="noopener" href="https://love.163.com/">https://love.163.com</a></li>
<li>网易考拉 <a target="_blank" rel="noopener" href="https://www.kaola.com/">https://www.kaola.com</a></li>
<li>网易Lofter <a target="_blank" rel="noopener" href="http://www.lofter.com/">http://www.lofter.com</a></li>
</ul>
<h3 id="2、单点登录系统的好处"><a href="#2、单点登录系统的好处" class="headerlink" title="2、单点登录系统的好处"></a>2、单点登录系统的好处</h3><ol>
<li><strong>用户角度</strong> :用户能够做到一次登录多次使用，无需记录多套用户名和密码，省心。</li>
<li><strong>系统管理员角度</strong> : 管理员只需维护好一个统一的账号中心就可以了，方便。</li>
<li><strong>新系统开发角度:</strong> 新系统开发时只需直接对接统一的账号中心即可，简化开发流程，省时。</li>
</ol>
<h3 id="3、设计目标"><a href="#3、设计目标" class="headerlink" title="3、设计目标"></a>3、设计目标</h3><p>本篇文章也主要是为了探讨如何设计&amp;实现一个SSO系统</p>
<p>以下为需要实现的核心功能：</p>
<ul>
<li>单点登录</li>
<li>单点登出</li>
<li>支持跨域单点登录</li>
<li>支持跨域单点登出</li>
</ul>
<h2 id="二、SSO设计与实现"><a href="#二、SSO设计与实现" class="headerlink" title="二、SSO设计与实现"></a>二、SSO设计与实现</h2><h3 id="1、核心应用与依赖"><a href="#1、核心应用与依赖" class="headerlink" title="1、核心应用与依赖"></a>1、核心应用与依赖</h3><p><img src="https://img.ken.io/blog/sso/sso-system.png-kblb.png" alt="单点登录（SSO）设计"></p>
<table>
<thead>
<tr>
<th>应用/模块/对象</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>前台站点</td>
<td>需要登录的站点</td>
</tr>
<tr>
<td>SSO站点-登录</td>
<td>提供登录的页面</td>
</tr>
<tr>
<td>SSO站点-登出</td>
<td>提供注销登录的入口</td>
</tr>
<tr>
<td>SSO服务-登录</td>
<td>提供登录服务</td>
</tr>
<tr>
<td>SSO服务-登录状态</td>
<td>提供登录状态校验/登录信息查询的服务</td>
</tr>
<tr>
<td>SSO服务-登出</td>
<td>提供用户注销登录的服务</td>
</tr>
<tr>
<td>数据库</td>
<td>存储用户账户信息</td>
</tr>
<tr>
<td>缓存</td>
<td>存储用户的登录信息，通常使用Redis</td>
</tr>
</tbody></table>
<h3 id="2、用户登录状态的存储与校验"><a href="#2、用户登录状态的存储与校验" class="headerlink" title="2、用户登录状态的存储与校验"></a>2、用户登录状态的存储与校验</h3><p>常见的Web框架对于<a target="_blank" rel="noopener" href="https://ken.io/note/session-principle-skill">Session</a>的实现都是生成一个SessionId存储在浏览器Cookie中。然后将Session内容存储在服务器端内存中，这个 ken.io 在之前<a target="_blank" rel="noopener" href="https://ken.io/note/session-principle-skill">Session工作原理</a>中也提到过。整体也是借鉴这个思路。<br>用户登录成功之后，生成AuthToken交给客户端保存。如果是浏览器，就保存在Cookie中。如果是手机App就保存在App本地缓存中。本篇主要探讨基于Web站点的SSO。<br>用户在浏览需要登录的页面时，客户端将AuthToken提交给SSO服务校验登录状态/获取用户登录信息</p>
<p>对于登录信息的存储，建议采用Redis，使用Redis集群来存储登录信息，既可以保证高可用，又可以线性扩充。同时也可以让SSO服务满足负载均衡/可伸缩的需求。</p>
<table>
<thead>
<tr>
<th>对象</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>AuthToken</td>
<td>直接使用UUID/GUID即可，如果有验证AuthToken合法性需求，可以将UserName+时间戳加密生成，服务端解密之后验证合法性</td>
</tr>
<tr>
<td>登录信息</td>
<td>通常是将UserId，UserName缓存起来</td>
</tr>
</tbody></table>
<h3 id="3、用户登录-登录校验"><a href="#3、用户登录-登录校验" class="headerlink" title="3、用户登录/登录校验"></a>3、用户登录/登录校验</h3><ul>
<li>登录时序图</li>
</ul>
<p><img src="https://img.ken.io/blog/sso/sso-login-sequence.png-kbrb.png" alt="SSO系统设计-登录时序图"></p>
<p>按照上图，用户登录后Authtoken保存在Cookie中。 domian= test. com<br>浏览器会将domain设置成 .test.com，<br>这样访问所有*.test.com的web站点，都会将Authtoken携带到服务器端。<br>然后通过SSO服务，完成对用户状态的校验/用户登录信息的获取</p>
<ul>
<li>登录信息获取/登录状态校验</li>
</ul>
<p><img src="https://img.ken.io/blog/sso/sso-logincheck-sequence.png-kbrb.png" alt="SSO系统设计-登录信息获取/登录状态校验"></p>
<h3 id="4、用户登出"><a href="#4、用户登出" class="headerlink" title="4、用户登出"></a>4、用户登出</h3><p>用户登出时要做的事情很简单：</p>
<ol>
<li>服务端清除缓存（Redis）中的登录状态</li>
<li>客户端清除存储的AuthToken</li>
</ol>
<ul>
<li>登出时序图</li>
</ul>
<p><img src="https://img.ken.io/blog/sso/sso-logout-sequence.png-kbrb.png" alt="SSO系统设计-用户登出"></p>
<h3 id="5、跨域登录、登出"><a href="#5、跨域登录、登出" class="headerlink" title="5、跨域登录、登出"></a>5、跨域登录、登出</h3><p>前面提到过，核心思路是客户端存储AuthToken，服务器端通过Redis存储登录信息。由于客户端是将AuthToken存储在Cookie中的。所以跨域要解决的问题，就是如何解决Cookie的跨域读写问题。</p>
<blockquote>
<p><strong>Cookie是不能跨域的</strong> ，比如我一个</p>
</blockquote>
<p>解决跨域的核心思路就是：</p>
<ul>
<li>登录完成之后通过回调的方式，将AuthToken传递给主域名之外的站点，该站点自行将AuthToken保存在当前域下的Cookie中。</li>
<li>登出完成之后通过回调的方式，调用非主域名站点的登出页面，完成设置Cookie中的AuthToken过期的操作。</li>
<li>跨域登录（主域名已登录）</li>
</ul>
<p><img src="https://img.ken.io/blog/sso/sso-crossdomain-login-loggedin-sequence.png-kbrb.png" alt="SSO系统设计-跨域登录（主域名已登录）"></p>
<ul>
<li>跨域登录（主域名未登录）</li>
</ul>
<p><img src="https://img.ken.io/blog/sso/sso-crossdomain-login-unlogin-sequence.png-kbrb.png" alt="SSO系统设计-跨域登录（主域名未登录）"></p>
<ul>
<li>跨域登出</li>
</ul>
<p><img src="https://img.ken.io/blog/sso/sso-crossdomain-logout-sequence.png-kbrb.png" alt="SSO系统设计-跨域登出"></p>
<h2 id="三、备注"><a href="#三、备注" class="headerlink" title="三、备注"></a>三、备注</h2><ul>
<li>关于方案</li>
</ul>
<p>这次设计方案更多是提供实现思路。如果涉及到APP用户登录等情况，在访问SSO服务时，增加对APP的签名验证就好了。当然，如果有无线网关，验证签名不是问题。</p>
<ul>
<li>关于时序图</li>
</ul>
<p>时序图中并没有包含所有场景，ken.io只列举了核心/主要场景，另外对于一些不影响理解思路的消息能省就省了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/authority-certification/SSO%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95%E7%9C%8B%E8%BF%99%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F%E4%BA%86/" data-id="cks75dy5p00047kvedi890tfe" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/authority-certification/JWT优缺点分析以及常见问题解决方案" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/authority-certification/JWT%E4%BC%98%E7%BC%BA%E7%82%B9%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.894Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="JWT-身份认证优缺点分析以及常见问题解决方案"><a href="#JWT-身份认证优缺点分析以及常见问题解决方案" class="headerlink" title="JWT 身份认证优缺点分析以及常见问题解决方案"></a>JWT 身份认证优缺点分析以及常见问题解决方案</h1><p>之前分享了一个使用 Spring Security 实现 JWT 身份认证的 Demo，文章地址：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485622&idx=1&sn=e9750ed63c47457ba1896db8dfceac6a&chksm=cea2477df9d5ce6b7af20e582c6c60b7408a6459b05b849394c45f04664d1651510bdee029f7&token=684071313&lang=zh_CN&scene=21#wechat_redirect">适合初学者入门 Spring Security With JWT 的 Demo</a>。 Demo 非常简单，没有介绍到 JWT 存在的一些问题。所以，单独抽了一篇文章出来介绍。为了完成这篇文章，我查阅了很多资料和文献，我觉得应该对大家有帮助。</p>
<p>相关阅读：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485626&idx=1&sn=3247aa9000693dd692de8a04ccffeec1&chksm=cea24771f9d5ce675ea0203633a95b68bfe412dc6a9d05f22d221161147b76161d1b470d54b3&token=684071313&lang=zh_CN&scene=21#wechat_redirect">《一问带你区分清楚Authentication,Authorization以及Cookie、Session、Token》</a></li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485622&idx=1&sn=e9750ed63c47457ba1896db8dfceac6a&chksm=cea2477df9d5ce6b7af20e582c6c60b7408a6459b05b849394c45f04664d1651510bdee029f7&token=684071313&lang=zh_CN&scene=21#wechat_redirect">适合初学者入门 Spring Security With JWT 的 Demo</a> </li>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485640&idx=1&sn=0ff147808318d53b371f16bb730c96ef&chksm=cea24703f9d5ce156ba67662f6f3f482330e8e6ebd9d44c61bf623083e9b941d8a180db6b0ea&token=1533246333&lang=zh_CN#rd">Spring Boot 使用 JWT 进行身份和权限验证</a></li>
</ul>
<h2 id="Token-认证的优势"><a href="#Token-认证的优势" class="headerlink" title="Token 认证的优势"></a>Token 认证的优势</h2><p> 相比于 Session 认证的方式来说，使用 token 进行身份认证主要有下面三个优势：</p>
<h3 id="1-无状态"><a href="#1-无状态" class="headerlink" title="1.无状态"></a>1.无状态</h3><p>token 自身包含了身份验证所需要的所有信息，使得我们的服务器不需要存储 Session 信息，这显然增加了系统的可用性和伸缩性，大大减轻了服务端的压力。但是，也正是由于 token 的无状态，也导致了它最大的缺点：当后端在token 有效期内废弃一个 token 或者更改它的权限的话，不会立即生效，一般需要等到有效期过后才可以。另外，当用户 Logout 的话，token 也还有效。除非，我们在后端增加额外的处理逻辑。</p>
<h3 id="2-有效避免了CSRF-攻击"><a href="#2-有效避免了CSRF-攻击" class="headerlink" title="2.有效避免了CSRF 攻击"></a>2.有效避免了CSRF 攻击</h3><p><strong>CSRF（Cross Site Request Forgery）</strong>一般被翻译为 <strong>跨站请求伪造</strong>，属于网络攻击领域范围。相比于 SQL 脚本注入、XSS等等安全攻击方式，CSRF 的知名度并没有它们高。但是,它的确是每个系统都要考虑的安全隐患，就连技术帝国 Google 的 Gmail 在早些年也被曝出过存在  CSRF 漏洞，这给 Gmail 的用户造成了很大的损失。</p>
<p>那么究竟什么是  <strong>跨站请求伪造</strong> 呢？说简单用你的身份去发送一些对你不友好的请求。举个简单的例子：</p>
<p>小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了10000元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">src</span>=<span class="string">http://www.mybank.com/Transfer?bankId</span>=<span class="string">11&amp;money</span>=<span class="string">10000</span>&gt;</span>科学理财，年盈利率过万<span class="tag">&lt;/&gt;</span></span><br></pre></td></tr></table></figure>

<p>导致这个问题很大的原因就是： Session 认证中 Cookie 中的 session_id 是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。</p>
<p><strong>那为什么 token 不会存在这种问题呢？</strong></p>
<p>我是这样理解的：一般情况下我们使用 JWT 的话，在我们登录成功获得 token 之后，一般会选择存放在  local storage 中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 token,这样就不会出现 CSRF 漏洞的问题。因为，即使有个你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 token 的，所以这个请求将是非法的。</p>
<p>但是这样会存在  XSS 攻击中被盗的风险，为了避免 XSS 攻击，你可以选择将 token 存储在标记为<code>httpOnly</code>  的cookie 中。但是，这样又导致了你必须自己提供CSRF保护。</p>
<p>具体采用上面哪两种方式存储 token 呢，大部分情况下存放在  local storage 下都是最好的选择，某些情况下可能需要存放在标记为<code>httpOnly</code>  的cookie 中会更好。</p>
<h3 id="3-适合移动端应用"><a href="#3-适合移动端应用" class="headerlink" title="3.适合移动端应用"></a>3.适合移动端应用</h3><p>使用 Session 进行身份认证的话，需要保存一份信息在服务器端，而且这种方式会依赖到 Cookie（需要 Cookie 保存 SessionId），所以不适合移动端。</p>
<p>但是，使用 token 进行身份认证就不会存在这种问题，因为只要 token 可以被客户端存储就能够使用，而且 token 还可以跨语言使用。</p>
<h3 id="4-单点登录友好"><a href="#4-单点登录友好" class="headerlink" title="4.单点登录友好"></a>4.单点登录友好</h3><p>使用 Session 进行身份认证的话，实现单点登录，需要我们把用户的 Session 信息保存在一台电脑上，并且还会遇到常见的 Cookie 跨域的问题。但是，使用 token 进行认证的话， token 被保存在客户端，不会存在这些问题。</p>
<h2 id="Token-认证常见问题以及解决办法"><a href="#Token-认证常见问题以及解决办法" class="headerlink" title="Token 认证常见问题以及解决办法"></a>Token 认证常见问题以及解决办法</h2><h3 id="1-注销登录等场景下-token-还有效"><a href="#1-注销登录等场景下-token-还有效" class="headerlink" title="1.注销登录等场景下 token 还有效"></a>1.注销登录等场景下 token 还有效</h3><p>与之类似的具体相关场景有：</p>
<ol>
<li>退出登录;</li>
<li>修改密码;</li>
<li>服务端修改了某个用户具有的权限或者角色；</li>
<li>用户的帐户被删除/暂停。</li>
<li>用户由管理员注销；</li>
</ol>
<p>这个问题不存在于 Session  认证方式中，因为在  Session  认证方式中，遇到这种情况的话服务端删除对应的 Session 记录即可。但是，使用 token 认证的方式就不好解决了。我们也说过了，token 一旦派发出去，如果后端不增加其他逻辑的话，它在失效之前都是有效的。那么，我们如何解决这个问题呢？查阅了很多资料，总结了下面几种方案：</p>
<ul>
<li><strong>将 token 存入内存数据库</strong>：将 token 存入 DB 中，redis 内存数据库在这里是是不错的选择。如果需要让某个 token 失效就直接从 redis 中删除这个 token 即可。但是，这样会导致每次使用 token 发送请求都要先从 DB 中查询 token 是否存在的步骤，而且违背了 JWT 的无状态原则。</li>
<li><strong>黑名单机制</strong>：和上面的方式类似，使用内存数据库比如 redis 维护一个黑名单，如果想让某个 token 失效的话就直接将这个 token 加入到 <strong>黑名单</strong> 即可。然后，每次使用 token 进行请求的话都会先判断这个 token 是否存在于黑名单中。</li>
<li><strong>修改密钥 (Secret)</strong> : 我们为每个用户都创建一个专属密钥，如果我们想让某个 token 失效，我们直接修改对应用户的密钥即可。但是，这样相比于前两种引入内存数据库带来了危害更大，比如：1⃣️如果服务是分布式的，则每次发出新的 token 时都必须在多台机器同步密钥。为此，你需要将必须将机密存储在数据库或其他外部服务中，这样和 Session 认证就没太大区别了。2⃣️如果用户同时在两个浏览器打开系统，或者在手机端也打开了系统，如果它从一个地方将账号退出，那么其他地方都要重新进行登录，这是不可取的。</li>
<li><strong>保持令牌的有效期限短并经常轮换</strong> ：很简单的一种方式。但是，会导致用户登录状态不会被持久记录，而且需要用户经常登录。</li>
</ul>
<p>对于修改密码后 token 还有效问题的解决还是比较容易的，说一种我觉得比较好的方式：<strong>使用用户的密码的哈希值对 token 进行签名。因此，如果密码更改，则任何先前的令牌将自动无法验证。</strong></p>
<h3 id="2-token-的续签问题"><a href="#2-token-的续签问题" class="headerlink" title="2.token 的续签问题"></a>2.token 的续签问题</h3><p>token 有效期一般都建议设置的不太长，那么 token 过期后如何认证，如何实现动态刷新 token，避免用户经常需要重新登录？</p>
<p>我们先来看看在 Session 认证中一般的做法：<strong>假如 session 的有效期30分钟，如果 30 分钟内用户有访问，就把 session 有效期被延长30分钟。</strong></p>
<ol>
<li><strong>类似于 Session 认证中的做法</strong>：这种方案满足于大部分场景。假设服务端给的 token 有效期设置为30分钟，服务端每次进行校验时，如果发现 token 的有效期马上快过期了，服务端就重新生成 token 给客户端。客户端每次请求都检查新旧token，如果不一致，则更新本地的token。这种做法的问题是仅仅在快过期的时候请求才会更新 token ,对客户端不是很友好。</li>
<li><strong>每次请求都返回新 token</strong> :这种方案的的思路很简单，但是，很明显，开销会比较大。</li>
<li><strong>token 有效期设置到半夜</strong> ：这种方案是一种折衷的方案，保证了大部分用户白天可以正常登录，适用于对安全性要求不高的系统。</li>
<li><strong>用户登录返回两个 token</strong> ：第一个是 acessToken ，它的过期时间 token 本身的过期时间比如半个小时，另外一个是 refreshToken 它的过期时间更长一点比如为1天。客户端登录后，将 accessToken和refreshToken 保存在本地，每次访问将 accessToken 传给服务端。服务端校验 accessToken 的有效性，如果过期的话，就将 refreshToken 传给服务端。如果有效，服务端就生成新的 accessToken 给客户端。否则，客户端就重新登录即可。该方案的不足是：1⃣️需要客户端来配合；2⃣️用户注销的时候需要同时保证两个  token 都无效；3⃣️重新请求获取 token  的过程中会有短暂 token 不可用的情况（可以通过在客户端设置定时器，当accessToken 快过期的时候，提前去通过 refreshToken 获取新的accessToken）。</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>JWT 最适合的场景是不需要服务端保存用户状态的场景，比如如果考虑到 token 注销和 token 续签的场景话，没有特别好的解决方案，大部分解决方案都给 token 加上了状态，这就有点类似 Session 认证了。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://learnku.com/articles/17883?order_by=vote_count&">JWT 超详细分析</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/devgorilla/how-to-log-out-when-using-jwt-a8c7823e8a6">https://medium.com/devgorilla/how-to-log-out-when-using-jwt-a8c7823e8a6</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@agungsantoso/csrf-protection-with-json-web-tokens-83e0f2fcbcc">https://medium.com/@agungsantoso/csrf-protection-with-json-web-tokens-83e0f2fcbcc</a></li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/21978658/invalidating-json-web-tokens">Invalidating JSON Web Tokens</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/authority-certification/JWT%E4%BC%98%E7%BC%BA%E7%82%B9%E5%88%86%E6%9E%90%E4%BB%A5%E5%8F%8A%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" data-id="cks75dy5q00057kvectwr1e1l" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/authority-certification/basis-of-authority-certification" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/authority-certification/basis-of-authority-certification/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.890Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="认证-Authentication-和授权-Authorization-的区别是什么？"><a href="#认证-Authentication-和授权-Authorization-的区别是什么？" class="headerlink" title="认证 (Authentication) 和授权 (Authorization)的区别是什么？"></a>认证 (Authentication) 和授权 (Authorization)的区别是什么？</h2><p>这是一个绝大多数人都会混淆的问题。首先先从读音上来认识这两个名词，很多人都会把它俩的读音搞混，所以我建议你先先去查一查这两个单词到底该怎么读，他们的具体含义是什么。</p>
<p>说简单点就是：</p>
<ul>
<li><strong>认证 (Authentication)：</strong> 你是谁。</li>
<li><strong>授权 (Authorization)：</strong> 你有权限干什么。</li>
</ul>
<p>稍微正式点（啰嗦点）的说法就是 ：</p>
<ul>
<li><strong>Authentication（认证）</strong> 是验证您的身份的凭据（例如用户名/用户 ID 和密码），通过这个凭据，系统得以知道你就是你，也就是说系统存在你这个用户。所以，Authentication 被称为身份/用户验证。</li>
<li><strong>Authorization（授权）</strong> 发生在 <strong>Authentication（认证）</strong> 之后。授权嘛，光看意思大家应该就明白，它主要掌管我们访问系统的权限。比如有些特定资源只能具有特定权限的人才能访问比如 admin，有些对系统资源操作比如删除、添加、更新只能特定人才具有。</li>
</ul>
<p>认证 ：</p>
<p><img src="https://img-blog.csdnimg.cn/20210604160908352.png"></p>
<p>授权：</p>
<p><img src="https://img-blog.csdnimg.cn/20210604161032412.png"></p>
<p>这两个一般在我们的系统中被结合在一起使用，目的就是为了保护我们系统的安全性。</p>
<h2 id="RBAC-模型了解吗？"><a href="#RBAC-模型了解吗？" class="headerlink" title="RBAC 模型了解吗？"></a>RBAC 模型了解吗？</h2><p>系统权限控制最常采用的访问控制模型就是 <strong>RBAC 模型</strong> 。</p>
<p><strong>什么是 RBAC 呢？</strong></p>
<p>RBAC 即基于角色的权限访问控制（Role-Based Access Control）。这是一种通过角色关联权限，角色同时又关联用户的授权的方式。</p>
<p>简单地说：一个用户可以拥有若干角色，每一个角色又可以被分配若干权限，这样就构造成“用户-角色-权限” 的授权模型。在这种模型中，用户与角色、角色与权限之间构成了多对多的关系，如下图</p>
<p><img src="https://cdn.jsdelivr.net/gh/javaguide-tech/blog-images-3@main/11-9/RBAC.png" alt="RBAC"></p>
<p><strong>在 RBAC 中，权限与角色相关联，用户通过成为适当角色的成员而得到这些角色的权限。这就极大地简化了权限的管理。</strong></p>
<p>本系统的权限设计相关的表如下（一共 5 张表，2 张用户建立表之间的联系）：</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/2020-11/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1-%E6%9D%83%E9%99%90.png"></p>
<p>通过这个权限模型，我们可以创建不同的角色并为不同的角色分配不同的权限范围（菜单）。</p>
<p><img src="https://cdn.jsdelivr.net/gh/javaguide-tech/blog-images-3@main/11-7/%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9D%97.png"></p>
<p>通常来说，如果系统对于权限控制要求比较严格的话，一般都会选择使用 RBAC 模型来做权限控制。</p>
<h2 id="什么是-Cookie-Cookie-的作用是什么"><a href="#什么是-Cookie-Cookie-的作用是什么" class="headerlink" title="什么是 Cookie ? Cookie 的作用是什么?"></a>什么是 Cookie ? Cookie 的作用是什么?</h2><p><img src="https://img-blog.csdnimg.cn/20210615162505880.png"></p>
<p><code>Cookie</code> 和 <code>Session</code> 都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。</p>
<p>维基百科是这样定义 <code>Cookie</code> 的：</p>
<blockquote>
<p><code>Cookies</code> 是某些网站为了辨别用户身份而储存在用户本地终端上的数据（通常经过加密）。</p>
</blockquote>
<p>简单来说： <strong><code>Cookie</code> 存放在客户端，一般用来保存用户信息</strong>。</p>
<p>下面是 <code>Cookie</code> 的一些应用案例：</p>
<ol>
<li>我们在 <code>Cookie</code> 中保存已经登录过的用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了。除此之外，<code>Cookie</code> 还能保存用户首选项，主题和其他设置信息。</li>
<li>使用 <code>Cookie</code> 保存 <code>Session</code> 或者 <code>Token</code> ，向后端发送请求的时候带上 <code>Cookie</code>，这样后端就能取到 <code>Session</code> 或者 <code>Token</code> 了。这样就能记录用户当前的状态了，因为 HTTP 协议是无状态的。</li>
<li><code>Cookie</code> 还可以用来记录和分析用户行为。举个简单的例子你在网上购物的时候，因为 HTTP 协议是没有状态的，如果服务器想要获取你在某个页面的停留状态或者看了哪些商品，一种常用的实现方式就是将这些信息存放在 <code>Cookie</code></li>
<li>……</li>
</ol>
<h2 id="如何在项目中使用-Cookie-呢？"><a href="#如何在项目中使用-Cookie-呢？" class="headerlink" title="如何在项目中使用 Cookie 呢？"></a>如何在项目中使用 Cookie 呢？</h2><p>我这里以 Spring Boot 项目为例。</p>
<p><strong>1)设置 <code>Cookie</code> 返回给客户端</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/change-username&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">setCookie</span><span class="params">(HttpServletResponse response)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建一个 cookie</span></span><br><span class="line">    Cookie cookie = <span class="keyword">new</span> Cookie(<span class="string">&quot;username&quot;</span>, <span class="string">&quot;Jovan&quot;</span>);</span><br><span class="line">    <span class="comment">//设置 cookie过期时间</span></span><br><span class="line">    cookie.setMaxAge(<span class="number">7</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span>); <span class="comment">// expires in 7 days</span></span><br><span class="line">    <span class="comment">//添加到 response 中</span></span><br><span class="line">    response.addCookie(cookie);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Username is changed!&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>2) 使用 Spring 框架提供的 <code>@CookieValue</code> 注解获取特定的 cookie 的值</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">readCookie</span><span class="params">(<span class="meta">@CookieValue(value = &quot;username&quot;, defaultValue = &quot;Atta&quot;)</span> String username)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Hey! My username is &quot;</span> + username;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>3) 读取所有的 <code>Cookie</code> 值</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/all-cookies&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">readAllCookies</span><span class="params">(HttpServletRequest request)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    Cookie[] cookies = request.getCookies();</span><br><span class="line">    <span class="keyword">if</span> (cookies != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.stream(cookies)</span><br><span class="line">                .map(c -&gt; c.getName() + <span class="string">&quot;=&quot;</span> + c.getValue()).collect(Collectors.joining(<span class="string">&quot;, &quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;No cookies&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>更多关于如何在 Spring Boot 中使用 <code>Cookie</code> 的内容可以查看这篇文章：<a target="_blank" rel="noopener" href="https://attacomsian.com/blog/cookies-spring-boot%E3%80%82">How to use cookies in Spring Boot</a> 。</p>
<h2 id="Cookie-和-Session-有什么区别？"><a href="#Cookie-和-Session-有什么区别？" class="headerlink" title="Cookie 和 Session 有什么区别？"></a>Cookie 和 Session 有什么区别？</h2><p><strong><code>Session</code> 的主要作用就是通过服务端记录用户的状态。</strong> 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 <code>Session</code> 之后就可以标识这个用户并且跟踪这个用户了。</p>
<p><code>Cookie</code> 数据保存在客户端(浏览器端)，<code>Session</code> 数据保存在服务器端。相对来说 <code>Session</code> 安全性更高。如果使用 <code>Cookie</code> 的一些敏感信息不要写入 <code>Cookie</code> 中，最好能将 <code>Cookie</code> 信息加密然后使用到的时候再去服务器端解密。</p>
<p><strong>那么，如何使用 <code>Session</code> 进行身份验证？</strong></p>
<h2 id="如何使用-Session-Cookie-方案进行身份验证？"><a href="#如何使用-Session-Cookie-方案进行身份验证？" class="headerlink" title="如何使用 Session-Cookie 方案进行身份验证？"></a>如何使用 Session-Cookie 方案进行身份验证？</h2><p>很多时候我们都是通过 <code>SessionID</code> 来实现特定的用户，<code>SessionID</code> 一般会选择存放在 Redis 中。举个例子：</p>
<ol>
<li>用户成功登陆系统，然后返回给客户端具有 <code>SessionID</code> 的 <code>Cookie</code></li>
<li>当用户向后端发起请求的时候会把 <code>SessionID</code> 带上，这样后端就知道你的身份状态了。</li>
</ol>
<p>关于这种认证方式更详细的过程如下：</p>
<p><img src="./images/basis-of-authority-certification/session-cookie.png"></p>
<ol>
<li>用户向服务器发送用户名、密码、验证码用于登陆系统。</li>
<li>服务器验证通过后，服务器为用户创建一个 <code>Session</code>，并将 <code>Session</code> 信息存储起来。</li>
<li>服务器向用户返回一个 <code>SessionID</code>，写入用户的 <code>Cookie</code>。</li>
<li>当用户保持登录状态时，<code>Cookie</code> 将与每个后续请求一起被发送出去。</li>
<li>服务器可以将存储在 <code>Cookie</code> 上的 <code>SessionID</code> 与存储在内存中或者数据库中的 <code>Session</code> 信息进行比较，以验证用户的身份，返回给用户客户端响应信息的时候会附带用户当前的状态。</li>
</ol>
<p>使用 <code>Session</code> 的时候需要注意下面几个点：</p>
<ol>
<li>依赖 <code>Session</code> 的关键业务一定要确保客户端开启了 <code>Cookie</code>。</li>
<li>注意 <code>Session</code> 的过期时间。</li>
</ol>
<p>另外，Spring Session 提供了一种跨多个应用程序或实例管理用户会话信息的机制。如果想详细了解可以查看下面几篇很不错的文章：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://codeboje.de/spring-Session-tutorial/">Getting Started with Spring Session</a></li>
<li><a target="_blank" rel="noopener" href="https://www.baeldung.com/spring-Session">Guide to Spring Session</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@gvnix/sticky-Sessions-with-spring-Session-redis-bdc6f7438cc3">Sticky Sessions with Spring Session &amp; Redis</a></li>
</ul>
<h2 id="多服务器节点下-Session-Cookie-方案如何做？"><a href="#多服务器节点下-Session-Cookie-方案如何做？" class="headerlink" title="多服务器节点下 Session-Cookie 方案如何做？"></a>多服务器节点下 Session-Cookie 方案如何做？</h2><p>Session-Cookie 方案在单体环境是一个非常好的身份认证方案。但是，当服务器水平拓展成多节点时，Session-Cookie 方案就要面临挑战了。</p>
<p>举个例子：假如我们部署了两份相同的服务 A，B，用户第一次登陆的时候 ，Nginx 通过负载均衡机制将用户请求转发到 A 服务器，此时用户的 Session 信息保存在 A 服务器。结果，用户第二次访问的时候 Nginx 将请求路由到 B 服务器，由于 B 服务器没有保存 用户的 Session 信息，导致用户需要重新进行登陆。</p>
<p><strong>我们应该如何避免上面这种情况的出现呢？</strong></p>
<p>有几个方案可供大家参考：</p>
<ol>
<li>某个用户的所有请求都通过特性的哈希策略分配给同一个服务器处理。这样的话，每个服务器都保存了一部分用户的 Session 信息。服务器宕机，其保存的所有 Session 信息就完全丢失了。</li>
<li>每一个服务器保存的 Session 信息都是互相同步的，也就是说每一个服务器都保存了全量的 Session 信息。每当一个服务器的 Session 信息发生变化，我们就将其同步到其他服务器。这种方案成本太大，并且，节点越多时，同步成本也越高。</li>
<li>单独使用一个所有服务器都能访问到的数据节点（比如缓存）来存放 Session 信息。为了保证高可用，数据节点尽量要避免是单点。</li>
</ol>
<h2 id="如果没有-Cookie-的话-Session-还能用吗？"><a href="#如果没有-Cookie-的话-Session-还能用吗？" class="headerlink" title="如果没有 Cookie 的话 Session 还能用吗？"></a>如果没有 Cookie 的话 Session 还能用吗？</h2><p>这是一道经典的面试题！</p>
<p>一般是通过 <code>Cookie</code> 来保存 <code>SessionID</code> ，假如你使用了 <code>Cookie</code> 保存 <code>SessionID</code> 的方案的话， 如果客户端禁用了 <code>Cookie</code>，那么 <code>Session</code> 就无法正常工作。</p>
<p>但是，并不是没有 <code>Cookie</code> 之后就不能用 <code>Session</code> 了，比如你可以将 <code>SessionID</code> 放在请求的 <code>url</code> 里面<code>https://javaguide.cn/?Session_id=xxx</code> 。这种方案的话可行，但是安全性和用户体验感降低。当然，为了你也可以对 <code>SessionID</code> 进行一次加密之后再传入后端。</p>
<h2 id="为什么-Cookie-无法防止-CSRF-攻击，而-Token-可以？"><a href="#为什么-Cookie-无法防止-CSRF-攻击，而-Token-可以？" class="headerlink" title="为什么 Cookie 无法防止 CSRF 攻击，而 Token 可以？"></a>为什么 Cookie 无法防止 CSRF 攻击，而 Token 可以？</h2><p><strong>CSRF（Cross Site Request Forgery）</strong>一般被翻译为 <strong>跨站请求伪造</strong> 。那么什么是 <strong>跨站请求伪造</strong> 呢？说简单用你的身份去发送一些对你不友好的请求。举个简单的例子：</p>
<p>小壮登录了某网上银行，他来到了网上银行的帖子区，看到一个帖子下面有一个链接写着“科学理财，年盈利率过万”，小壮好奇的点开了这个链接，结果发现自己的账户少了 10000 元。这是这么回事呢？原来黑客在链接中藏了一个请求，这个请求直接利用小壮的身份给银行发送了一个转账请求,也就是通过你的 Cookie 向银行发出请求。</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">src</span>=<span class="string">http://www.mybank.com/Transfer?bankId</span>=<span class="string">11&amp;money</span>=<span class="string">10000</span>&gt;</span>科学理财，年盈利率过万<span class="tag">&lt;/&gt;</span></span><br></pre></td></tr></table></figure>

<p>上面也提到过，进行 <code>Session</code> 认证的时候，我们一般使用 <code>Cookie</code> 来存储 <code>SessionId</code>,当我们登陆后后端生成一个 <code>SessionId</code> 放在 Cookie 中返回给客户端，服务端通过 Redis 或者其他存储工具记录保存着这个 <code>SessionId</code>，客户端登录以后每次请求都会带上这个 <code>SessionId</code>，服务端通过这个 <code>SessionId</code> 来标示你这个人。如果别人通过 <code>Cookie</code> 拿到了 <code>SessionId</code> 后就可以代替你的身份访问系统了。</p>
<p><code>Session</code> 认证中 <code>Cookie</code> 中的 <code>SessionId</code> 是由浏览器发送到服务端的，借助这个特性，攻击者就可以通过让用户误点攻击链接，达到攻击效果。</p>
<p>但是，我们使用 <code>Token</code> 的话就不会存在这个问题，在我们登录成功获得 <code>Token</code> 之后，一般会选择存放在 <code>localStorage</code> （浏览器本地存储）中。然后我们在前端通过某些方式会给每个发到后端的请求加上这个 <code>Token</code>,这样就不会出现 CSRF 漏洞的问题。因为，即使有个你点击了非法链接发送了请求到服务端，这个非法请求是不会携带 <code>Token</code> 的，所以这个请求将是非法的。</p>
<p><img src="https://img-blog.csdnimg.cn/20210615161108272.png"></p>
<p>需要注意的是不论是 <code>Cookie</code> 还是 <code>Token</code> 都无法避免 <strong>跨站脚本攻击（Cross Site Scripting）XSS</strong> 。</p>
<blockquote>
<p>跨站脚本攻击（Cross Site Scripting）缩写为 CSS 但这会与层叠样式表（Cascading Style Sheets，CSS）的缩写混淆。因此，有人将跨站脚本攻击缩写为 XSS。</p>
</blockquote>
<p>XSS 中攻击者会用各种方式将恶意代码注入到其他用户的页面中。就可以通过脚本盗用信息比如 <code>Cookie</code> 。</p>
<p>推荐阅读：<a target="_blank" rel="noopener" href="https://tech.meituan.com/2018/10/11/fe-security-csrf.html">如何防止 CSRF 攻击？—美团技术团队</a></p>
<h2 id="什么是-Token-什么是-JWT"><a href="#什么是-Token-什么是-JWT" class="headerlink" title="什么是 Token?什么是 JWT?"></a>什么是 Token?什么是 JWT?</h2><p>我们在前面的问题中探讨了使用 <code>Session</code> 来鉴别用户的身份，并且给出了几个 Spring Session 的案例分享。 我们知道 <code>Session</code> 信息需要保存一份在服务器端。这种方式会带来一些麻烦，比如需要我们保证保存 <code>Session</code> 信息服务器的可用性、不适合移动端（依赖 <code>Cookie</code>）等等。</p>
<p>有没有一种不需要自己存放 <code>Session</code> 信息就能实现身份验证的方式呢？使用 <code>Token</code> 即可！<strong>JWT</strong> （JSON Web Token） 就是这种方式的实现，通过这种方式服务器端就不需要保存 <code>Session</code> 数据了，只用在客户端保存服务端返回给客户的 <code>Token</code> 就可以了，扩展性得到提升。</p>
<p><strong>JWT 本质上就一段签名的 JSON 格式的数据。由于它是带有签名的，因此接收者便可以验证它的真实性。</strong></p>
<p>下面是 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7519">RFC 7519</a> 对 JWT 做的较为正式的定义。</p>
<blockquote>
<p>JSON Web Token (JWT) is a compact, URL-safe means of representing claims to be transferred between two parties. The claims in a JWT are encoded as a JSON object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or integrity protected with a Message Authentication Code (MAC) and/or encrypted. ——<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7519">JSON Web Token (JWT)</a></p>
</blockquote>
<p>JWT 由 3 部分构成:</p>
<ol>
<li><strong>Header</strong> : 描述 JWT 的元数据，定义了生成签名的算法以及 <code>Token</code> 的类型。</li>
<li><strong>Payload</strong> : 用来存放实际需要传递的数据</li>
<li><strong>Signature（签名）</strong> ：服务器通过<code>Payload</code>、<code>Header</code>和一个密钥(<code>secret</code>)使用 <code>Header</code> 里面指定的签名算法（默认是 HMAC SHA256）生成。</li>
</ol>
<h2 id="如何基于-Token-进行身份验证？"><a href="#如何基于-Token-进行身份验证？" class="headerlink" title="如何基于 Token 进行身份验证？"></a>如何基于 Token 进行身份验证？</h2><p>在基于 Token 进行身份验证的的应用程序中，服务器通过<code>Payload</code>、<code>Header</code>和一个密钥(<code>secret</code>)创建令牌（<code>Token</code>）并将 <code>Token</code> 发送给客户端，客户端将 <code>Token</code> 保存在 Cookie 或者 localStorage 里面，以后客户端发出的所有请求都会携带这个令牌。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP Header 的 Authorization 字段中：<code>Authorization: Bearer Token</code>。</p>
<p><img src="./images/basis-of-authority-certification/jwt.png" alt="jwt"></p>
<ol>
<li>用户向服务器发送用户名和密码用于登陆系统。</li>
<li>身份验证服务响应并返回了签名的 JWT，上面包含了用户是谁的内容。</li>
<li>用户以后每次向后端发请求都在 <code>Header</code> 中带上 JWT。</li>
<li>服务端检查 JWT 并从中获取用户相关信息。</li>
</ol>
<h2 id="什么是-SSO"><a href="#什么是-SSO" class="headerlink" title="什么是 SSO?"></a>什么是 SSO?</h2><p>SSO(Single Sign On)即单点登录说的是用户登陆多个子系统的其中一个就有权访问与其相关的其他系统。举个例子我们在登陆了京东金融之后，我们同时也成功登陆京东的京东超市、京东国际、京东生鲜等子系统。</p>
<p><img src="./images/basis-of-authority-certification/sso.png" alt="sso"></p>
<h2 id="什么是-OAuth-2-0？"><a href="#什么是-OAuth-2-0？" class="headerlink" title="什么是 OAuth 2.0？"></a>什么是 OAuth 2.0？</h2><p>OAuth 是一个行业的标准授权协议，主要用来授权第三方应用获取有限的权限。而 OAuth 2.0 是对 OAuth 1.0 的完全重新设计，OAuth 2.0 更快，更容易实现，OAuth 1.0 已经被废弃。详情请见：<a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc6749">rfc6749</a>。</p>
<p>实际上它就是一种授权机制，它的最终目的是为第三方应用颁发一个有时效性的令牌 Token，使得第三方应用能够通过该令牌获取相关的资源。</p>
<p>OAuth 2.0 比较常用的场景就是第三方登录，当你的网站接入了第三方登录的时候一般就是使用的 OAuth 2.0 协议。</p>
<p>另外，现在 OAuth 2.0 也常见于支付场景（微信支付、支付宝支付）和开发平台（微信开放平台、阿里开放平台等等）。</p>
<p>微信支付账户相关参数：</p>
<p><img src="./images/basis-of-authority-certification/%E5%BE%AE%E4%BF%A1%E6%94%AF%E4%BB%98-fnglfdlgdfj.png"></p>
<p>下图是 <a target="_blank" rel="noopener" href="https://api.slack.com/legacy/oauth">Slack OAuth 2.0 第三方登录</a>的示意图：</p>
<p><img src="https://img-blog.csdnimg.cn/20210615151716340.png"></p>
<p><strong>推荐阅读：</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2019/04/oauth_design.html">OAuth 2.0 的一个简单解释</a></li>
<li><a target="_blank" rel="noopener" href="https://deepzz.com/post/what-is-oauth2-protocol.html">10 分钟理解什么是 OAuth 2.0 协议</a></li>
<li><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2019/04/oauth-grant-types.html">OAuth 2.0 的四种方式</a></li>
<li><a target="_blank" rel="noopener" href="http://www.ruanyifeng.com/blog/2019/04/github-oauth.html">GitHub OAuth 第三方登录示例教程</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/authority-certification/basis-of-authority-certification/" data-id="cks75dy68000j7kve0d0k0xqt" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-system-design/读写分离&amp;分库分表" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/08/11/system-design/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB&%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/" class="article-date">
  <time class="dt-published" datetime="2021-08-11T07:03:46.884Z" itemprop="datePublished">2021-08-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>大家好呀！今天和小伙伴们聊聊读写分离以及分库分表。</p>
<p>相信很多小伙伴们对于这两个概念已经比较熟悉了，这篇文章全程都是大白话的形式，希望能够给你带来不一样的感受。</p>
<p>如果你之前不太了解这两个概念，那我建议你搞懂之后，可以把自己对于读写分离以及分库分表的理解讲给你的同事/朋友听听。</p>
<p><strong>原创不易，若有帮助，点赞/分享就是对我最大的鼓励！</strong></p>
<p><em>个人能力有限。如果文章有任何需要补充/完善/修改的地方，欢迎在评论区指出，共同进步！</em></p>
<h1 id="读写分离-amp-分库分表"><a href="#读写分离-amp-分库分表" class="headerlink" title="读写分离&amp;分库分表"></a>读写分离&amp;分库分表</h1><h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><h3 id="何为读写分离？"><a href="#何为读写分离？" class="headerlink" title="何为读写分离？"></a>何为读写分离？</h3><p>见名思意，根据读写分离的名字，我们就可以知道：<strong>读写分离主要是为了将对数据库的读写操作分散到不同的数据库节点上。</strong> 这样的话，就能够小幅提升写性能，大幅提升读性能。</p>
<p>我简单画了一张图来帮助不太清楚读写分离的小伙伴理解。</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/java-guide-blog/9c624bc130d053860a5089cb9a53310a.png" alt="读写分离"></p>
<p>一般情况下，我们都会选择一主多从，也就是一台主数据库负责写，其他的从数据库负责读。主库和从库之间会进行数据同步，以保证从库中数据的准确性。这样的架构实现起来比较简单，并且也符合系统的写少读多的特点。</p>
<h3 id="读写分离会带来什么问题？如何解决？"><a href="#读写分离会带来什么问题？如何解决？" class="headerlink" title="读写分离会带来什么问题？如何解决？"></a>读写分离会带来什么问题？如何解决？</h3><p>读写分离对于提升数据库的并发非常有效，但是，同时也会引来一个问题：主库和从库的数据存在延迟，比如你写完主库之后，主库的数据同步到从库是需要时间的，这个时间差就导致了主库和从库的数据不一致性问题。这也就是我们经常说的 <strong>主从同步延迟</strong> 。</p>
<p>主从同步延迟问题的解决，没有特别好的一种方案（可能是我太菜了，欢迎评论区补充）。你可以根据自己的业务场景，参考一下下面几种解决办法。</p>
<p><strong>1.强制将读请求路由到主库处理。</strong></p>
<p>既然你从库的数据过期了，那我就直接从主库读取嘛！这种方案虽然会增加主库的压力，但是，实现起来比较简单，也是我了解到的使用最多的一种方式。</p>
<p>比如 <code>Sharding-JDBC</code> 就是采用的这种方案。通过使用 Sharding-JDBC 的 <code>HintManager</code> 分片键值管理器，我们可以强制使用主库。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HintManager hintManager = HintManager.getInstance();</span><br><span class="line">hintManager.setMasterRouteOnly();</span><br><span class="line"><span class="comment">// 继续JDBC操作</span></span><br></pre></td></tr></table></figure>

<p>对于这种方案，你可以将那些必须获取最新数据的读请求都交给主库处理。</p>
<p><strong>2.延迟读取。</strong></p>
<p>还有一些朋友肯定会想既然主从同步存在延迟，那我就在延迟之后读取啊，比如主从同步延迟 0.5s,那我就 1s 之后再读取数据。这样多方便啊！方便是方便，但是也很扯淡。</p>
<p>不过，如果你是这样设计业务流程就会好很多：对于一些对数据比较敏感的场景，你可以在完成写请求之后，避免立即进行请求操作。比如你支付成功之后，跳转到一个支付成功的页面，当你点击返回之后才返回自己的账户。</p>
<p>另外，<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100020801?code=ieY8HeRSlDsFbuRtggbBQGxdTh-1jMASqEIeqzHAKrI=">《MySQL 实战 45 讲》</a>这个专栏中的<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/77636">《读写分离有哪些坑？》</a>这篇文章还介绍了很多其他比较实际的解决办法，感兴趣的小伙伴可以自行研究一下。</p>
<h3 id="如何实现读写分离？"><a href="#如何实现读写分离？" class="headerlink" title="如何实现读写分离？"></a>如何实现读写分离？</h3><p>不论是使用哪一种读写分离具体的实现方案，想要实现读写分离一般包含如下几步：</p>
<ol>
<li>部署多台数据库，选择一种的一台作为主数据库，其他的一台或者多台作为从数据库。</li>
<li>保证主数据库和从数据库之间的数据是实时同步的，这个过程也就是我们常说的<strong>主从复制</strong>。</li>
<li>系统将写请求交给主数据库处理，读请求交给从数据库处理。</li>
</ol>
<p>落实到项目本身的话，常用的方式有两种：</p>
<p><strong>1.代理方式</strong></p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/java-guide-blog/461112716e30db118f4c784adc6e2ff7.png" alt="读写分离-代理层"></p>
<p>我们可以在应用和数据中间加了一个代理层。应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中。</p>
<p>提供类似功能的中间件有 <strong>MySQL Router</strong>（官方）、<strong>Atlas</strong>（基于 MySQL Proxy）、<strong>Maxscale</strong>、<strong>MyCat</strong>。</p>
<p><strong>2.组件方式</strong></p>
<p>在这种方式中，我们可以通过引入第三方组件来帮助我们读写请求。</p>
<p>这也是我比较推荐的一种方式。这种方式目前在各种互联网公司中用的最多的，相关的实际的案例也非常多。如果你要采用这种方式的话，推荐使用 <code>sharding-jdbc</code> ，直接引入 jar 包即可使用，非常方便。同时，也节省了很多运维的成本。</p>
<p>你可以在 shardingsphere 官方找到<a target="_blank" rel="noopener" href="https://shardingsphere.apache.org/document/legacy/3.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/">sharding-jdbc 关于读写分离的操作</a>。</p>
<h3 id="主从复制原理了解么？"><a href="#主从复制原理了解么？" class="headerlink" title="主从复制原理了解么？"></a>主从复制原理了解么？</h3><p>MySQL binlog(binary log 即二进制日志文件) 主要记录了 MySQL 数据库中数据的所有变化(数据库执行的所有 DDL 和 DML 语句)。因此，我们根据主库的 MySQL binlog 日志就能够将主库的数据同步到从库中。</p>
<p>更具体和详细的过程是这个样子的（图片来自于：<a target="_blank" rel="noopener" href="https://www.toptal.com/mysql/mysql-master-slave-replication-tutorial">《MySQL Master-Slave Replication on the Same Machine》</a>）：</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/java-guide-blog/78816271d3ab52424bfd5ad3086c1a0f.png" alt="MySQL主从复制"></p>
<ol>
<li>主库将数据库中数据的变化写入到 binlog</li>
<li>从库连接主库</li>
<li>从库会创建一个 I/O 线程向主库请求更新的 binlog</li>
<li>主库会创建一个 binlog dump 线程来发送 binlog ，从库中的 I/O 线程负责接收</li>
<li>从库的 I/O 线程将接收的 binlog 写入到 relay log 中。</li>
<li>从库的 SQL 线程读取 relay log 同步数据本地（也就是再执行一遍 SQL ）。</li>
</ol>
<p>怎么样？看了我对主从复制这个过程的讲解，你应该搞明白了吧!</p>
<p>你一般看到 binlog 就要想到主从复制。当然，除了主从复制之外，binlog 还能帮助我们实现数据恢复。</p>
<p>🌈 拓展一下：</p>
<p>不知道大家有没有使用过阿里开源的一个叫做 canal 的工具。这个工具可以帮助我们实现 MySQL 和其他数据源比如 Elasticsearch 或者另外一台 MySQL 数据库之间的数据同步。很显然，这个工具的底层原理肯定也是依赖 binlog。canal 的原理就是模拟 MySQL 主从复制的过程，解析 binlog 将数据同步到其他的数据源。</p>
<p>另外，像咱们常用的分布式缓存组件 Redis 也是通过主从复制实现的读写分离。</p>
<p>🌕 简单总结一下：</p>
<p><strong>MySQL 主从复制是依赖于 binlog 。另外，常见的一些同步 MySQL 数据到其他数据源的工具（比如 canal）的底层一般也是依赖 binlog 。</strong></p>
<h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><p>读写分离主要应对的是数据库读并发，没有解决数据库存储问题。试想一下：<strong>如果 MySQL 一张表的数据量过大怎么办?</strong></p>
<p>换言之，<strong>我们该如何解决 MySQL 的存储压力呢？</strong></p>
<p>答案之一就是 <strong>分库分表</strong>。</p>
<h3 id="何为分库？"><a href="#何为分库？" class="headerlink" title="何为分库？"></a>何为分库？</h3><p><strong>分库</strong> 就是将数据库中的数据分散到不同的数据库上。</p>
<p>下面这些操作都涉及到了分库：</p>
<ul>
<li>你将数据库中的用户表和用户订单表分别放在两个不同的数据库。</li>
<li>由于用户表数据量太大，你对用户表进行了水平切分，然后将切分后的 2 张用户表分别放在两个不同的数据库。</li>
</ul>
<h3 id="何为分表？"><a href="#何为分表？" class="headerlink" title="何为分表？"></a>何为分表？</h3><p><strong>分表</strong> 就是对单表的数据进行拆分，可以是垂直拆分，也可以是水平拆分。</p>
<p><strong>何为垂直拆分？</strong></p>
<p>简单来说，垂直拆分是对数据表列的拆分，把一张列比较多的表拆分为多张表。</p>
<p>举个例子：我们可以将用户信息表中的一些列单独抽出来作为一个表。</p>
<p><strong>何为水平拆分？</strong></p>
<p>简单来说，水平拆分是对数据表行的拆分，把一张行比较多的表拆分为多张表。</p>
<p>举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。</p>
<p><a target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100006601?code=i00Nq3pHUcUj04ZWy70NCRl/D2Lfj8GVzcGzZ3Wf5Ug=">《从零开始学架构》</a> 中的有一张图片对于垂直拆分和水平拆分的描述还挺直观的。</p>
<p><img src="https://guide-blog-images.oss-cn-shenzhen.aliyuncs.com/java-guide-blog/662ea3bda90061d0b40177e3a46fefc3.jpg"></p>
<h3 id="什么情况下需要分库分表？"><a href="#什么情况下需要分库分表？" class="headerlink" title="什么情况下需要分库分表？"></a>什么情况下需要分库分表？</h3><p>遇到下面几种场景可以考虑分库分表：</p>
<ul>
<li>单表的数据达到千万级别以上，数据库读写速度比较缓慢（分表）。</li>
<li>数据库中的数据占用的空间越来越大，备份时间越来越长（分库）。</li>
<li>应用的并发量太大（分库）。</li>
</ul>
<h3 id="分库分表会带来什么问题呢？"><a href="#分库分表会带来什么问题呢？" class="headerlink" title="分库分表会带来什么问题呢？"></a>分库分表会带来什么问题呢？</h3><p>记住，你在公司做的任何技术决策，不光是要考虑这个技术能不能满足我们的要求，是否适合当前业务场景，还要重点考虑其带来的成本。</p>
<p>引入分库分表之后，会给系统带来什么挑战呢？</p>
<ul>
<li><strong>join 操作</strong> ： 同一个数据库中的表分布在了不同的数据库中，导致无法使用 join 操作。这样就导致我们需要手动进行数据的封装，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。</li>
<li><strong>事务问题</strong> ：同一个数据库中的表分布在了不同的数据库中，如果单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了。</li>
<li><strong>分布式 id</strong> ：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足生成的主键唯一了。我们如何为不同的数据节点生成全局唯一主键呢？这个时候，我们就需要为我们的系统引入分布式 id 了。</li>
<li>……</li>
</ul>
<p>另外，引入分库分表之后，一般需要 DBA 的参与，同时还需要更多的数据库服务器，这些都属于成本。</p>
<h3 id="分库分表有没有什么比较推荐的方案？"><a href="#分库分表有没有什么比较推荐的方案？" class="headerlink" title="分库分表有没有什么比较推荐的方案？"></a>分库分表有没有什么比较推荐的方案？</h3><p>ShardingSphere 项目（包括 Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar）是当当捐入 Apache 的，目前主要由京东数科的一些巨佬维护。</p>
<p><img src="https://img-blog.csdnimg.cn/img_convert/60649996bfc69acb1953063dddf0c2e6.png"></p>
<p>ShardingSphere 绝对可以说是当前分库分表的首选！ShardingSphere 的功能完善，除了支持读写分离和分库分表，还提供分布式事务、数据库治理等功能。</p>
<p>另外，ShardingSphere 的生态体系完善，社区活跃，文档完善，更新和发布比较频繁。</p>
<p>艿艿之前写了一篇分库分表的实战文章，各位朋友可以看看：<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/A2MYOFT7SP-7kGOon8qJaw">《芋道 Spring Boot 分库分表入门》</a> 。</p>
<h3 id="分库分表后，数据怎么迁移呢？"><a href="#分库分表后，数据怎么迁移呢？" class="headerlink" title="分库分表后，数据怎么迁移呢？"></a>分库分表后，数据怎么迁移呢？</h3><p>分库分表之后，我们如何将老库（单库单表）的数据迁移到新库（分库分表后的数据库系统）呢？</p>
<p>比较简单同时也是非常常用的方案就是<strong>停机迁移</strong>，写个脚本老库的数据写到新库中。比如你在凌晨 2 点，系统使用的人数非常少的时候，挂一个公告说系统要维护升级预计 1 小时。然后，你写一个脚本将老库的数据都同步到新库中。</p>
<p>如果你不想停机迁移数据的话，也可以考虑<strong>双写方案</strong>。双写方案是针对那种不能停机迁移的场景，实现起来要稍微麻烦一些。具体原理是这样的：</p>
<ul>
<li>我们对老库的更新操作（增删改），同时也要写入新库（双写）。如果操作的数据不存在于新库的话，需要插入到新库中。 这样就能保证，咱们新库里的数据是最新的。</li>
<li>在迁移过程，双写只会让被更新操作过的老库中的数据同步到新库，我们还需要自己写脚本将老库中的数据和新库的数据做比对。如果新库中没有，那咱们就把数据插入到新库。如果新库有，旧库没有，就把新库对应的数据删除（冗余数据清理）。</li>
<li>重复上一步的操作，直到老库和新库的数据一致为止。</li>
</ul>
<p>想要在项目中实施双写还是比较麻烦的，很容易会出现问题。我们可以借助上面提到的数据库同步工具 Canal 做增量数据迁移（还是依赖 binlog，开发和维护成本较低）。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/08/11/system-design/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB&%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/" data-id="cks75dy5o00037kvedmrp4d86" data-title="" class="article-share-link">分享</a>
      
      
      
    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/2/">&laquo; 上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/">下一页 &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/08/11/system-design/website-architecture/%E5%85%B3%E4%BA%8E%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E6%87%82%E7%9A%8410%E4%B8%AA%E9%97%AE%E9%A2%98/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/08/11/system-design/website-architecture/8%20%E5%BC%A0%E5%9B%BE%E8%AF%BB%E6%87%82%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E6%8A%80%E6%9C%AF%E6%9E%B6%E6%9E%84/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/08/11/system-design/micro-service/%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88%E6%80%BB%E7%BB%93/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/08/11/system-design/micro-service/spring-cloud/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/08/11/system-design/high-availability/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F%E8%A6%81%E8%80%83%E8%99%91%E5%93%AA%E4%BA%9B%E5%9C%B0%E6%96%B9/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>